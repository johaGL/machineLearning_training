{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GALVIS Johanna\n",
    "# <font color='cadetblue'>SUPERVISED LEARNING (TP-AS)</font> \n",
    "\n",
    "# I. Feature engineering & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. 1 data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=10000,suppress=True)\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the data\n",
    "credd = pd.read_csv(\"credit_scoring.csv\", sep=\";\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seniority</th>\n",
       "      <th>Home</th>\n",
       "      <th>Time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital</th>\n",
       "      <th>Records</th>\n",
       "      <th>Job</th>\n",
       "      <th>Expenses</th>\n",
       "      <th>Income</th>\n",
       "      <th>Assets</th>\n",
       "      <th>Debt</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Price</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2985.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Seniority  Home  Time   Age  Marital  Records  Job  Expenses  Income  \\\n",
       "0        9.0   1.0  60.0  30.0      0.0      1.0  1.0      73.0   129.0   \n",
       "1       17.0   1.0  60.0  58.0      1.0      1.0  0.0      48.0   131.0   \n",
       "2       10.0   0.0  36.0  46.0      0.0      2.0  1.0      90.0   200.0   \n",
       "\n",
       "   Assets  Debt  Amount   Price  Status  \n",
       "0     0.0   0.0   800.0   846.0       1  \n",
       "1     0.0   0.0  1000.0  1658.0       1  \n",
       "2  3000.0   0.0  2000.0  2985.0       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credd.head(3) # variable bi-class 'Status' is the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4375, 14), 'NA values ==> 0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credd.shape, f\"NA values ==> {credd.isnull().sum().sum()}\" #shape and CHECK IF empty (NaN, NA) cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "YstatusPS = credd.pop('Status') # detach this column from df\n",
    "Ystatus = YstatusPS.to_numpy() # the numpy Y vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4375,), (4375, 13))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ystatus.shape, credd.shape # verifying dimensions both objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good payers 72.21 %, Bad payers : 27.79%\n"
     ]
    }
   ],
   "source": [
    "GP = 100*np.sum(Ystatus==1)/len(Ystatus) #good payers\n",
    "BP = 100*np.sum(Ystatus==0)/len(Ystatus) #bad payers\n",
    "print ('Good payers {0:.2f} %, Bad payers : {1:.2f}%'.format(GP,BP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4375, 13)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xcred = credd.values  # the numpy X array\n",
    "Xcred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([i for i in credd.head(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X into two matrices, same for Y vector.\n",
    "# '_train' dataset is for learning phase and '_test' dataset is for prediction\n",
    "Xcr_train, Xcr_test, Ycr_train, Ycr_test = model_selection.train_test_split(\n",
    "Xcred, Ystatus, test_size=0.5, random_state=1) # random_state :  effect on the reproducibility of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective on 'credit_scoring' data is to predict good payers, in order to decide which client can have his/her credit approved.  We have splitted X matrix (4375 clients x 13 numerical variables) and Y class vector (4375 binary values) into two parts each, 'train' part for **learning** the model and the other one to **predict** Y class from a given X_test matrix. We need to select and train the most appropriate machine learning classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.2 Learning and evaluating models\n",
    "Applying CART, KNN and Multilayer Perceptron to raw matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=1) # \"Gini\" is default\n",
    "dtc.fit(Xcr_train, Ycr_train) \n",
    "# normalization not compulsory, but missing values can yield errors. Already checked above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure()\n",
    "#_ = tree.plot_tree(dtc)\n",
    "#fig.show(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this tree is wide and deep, in this case one solution can be pruning the tree, for the moment we will check predictions using the model without prunning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 325  279]\n",
      " [ 318 1266]]\n"
     ]
    }
   ],
   "source": [
    "predicted = dtc.predict(Xcr_test)\n",
    "print(confusion_matrix(Ycr_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAUTION: previous chunk via 'confusion_matrix' sklearn function yields a matrix following this less usual orientation:\n",
    "\n",
    "|     | pred => |   0   |   1   | \n",
    "|-----|---------|-------|-------|\n",
    "|   o |  0      |  TN   |  FP   | \n",
    "|   b |  1      |  FN   |  TP   | \n",
    "|   s |         |       |       |\n",
    "\n",
    "\n",
    "More often the matrix is presented in this way (wikipedia for example):\n",
    "\n",
    "|     | obs =>  |   1   |   0   | \n",
    "|-----|---------|-------|-------|\n",
    "|   p |  1      |  TP   |  FP   | \n",
    "|   r |  0      |  FN   |  TN   | \n",
    "|   d |         |       |       |\n",
    "\n",
    "FP : a customer being predicted default but in reality he/she's a good payer.\n",
    "FN : a customer being predicted good payer but who will actually default.\n",
    "For self-educational purposes, I created function `getcalcCM` to calculate confusion matrix derived scores: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 325  279]\n",
      " [ 318 1266]]\n",
      "is my accuracy equal to metrics.accuracy_score?: True\n",
      "is my accuracy equal to metrics.recall_score?: True\n"
     ]
    }
   ],
   "source": [
    "def getcalcCM(confusionMat, poplength): #confusion matrix MUST EXIST in this order (TEST, predicted)\n",
    "    specificity = confusionMat[0,0] / confusionMat[0].sum() #TN/TN+FP\n",
    "    precision = confusionMat[1,1] / (confusionMat[0,1]+confusionMat[1,1]) # TP/(TP+FP)\n",
    "    accuracy = (confusionMat[0,0]+confusionMat[1,1]) / poplength  \n",
    "    recall =  confusionMat[1,1] / confusionMat[1].sum()\n",
    "    return accuracy, precision, recall, specificity\n",
    "# check my estimators custom function is ok:\n",
    "CM = confusion_matrix(Ycr_test, predicted)\n",
    "print(CM)\n",
    "m,n,r,s = getcalcCM(CM, len(Ycr_test))\n",
    "print(\"is my accuracy equal to metrics.accuracy_score?: {}\".format(m == accuracy_score(Ycr_test,predicted)))\n",
    "print(\"is my accuracy equal to metrics.recall_score?: {}\".format(r == recall_score(Ycr_test,predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARING THREE CLASSIFIERS : CART, KNN, MLP\n",
    "def CART_KNN_MLP(Xtrain, Xtest, Ytrain, Ytest):\n",
    "    dtc = DecisionTreeClassifier(random_state=1) # \"Gini\" is default\n",
    "    dtc.fit(Xtrain, Ytrain) \n",
    "    pred_tree = dtc.predict(Xtest)\n",
    "    C = confusion_matrix(Ytest,pred_tree)\n",
    "    print('CART (decision tree)')\n",
    "    acc, pr, rc, sp = getcalcCM(C, len(Ytest))\n",
    "    print('  accuracy:{0:.2f}%, precision : {1:.2f}%, recall : {2:.2f}%'.format(acc*100, pr*100, rc*100))\n",
    "    \n",
    "    knnmod = KNeighborsClassifier(n_neighbors = 5)\n",
    "    knnmod.fit(Xtrain, Ytrain)\n",
    "    predicted_knn = knnmod.predict(Xtest)\n",
    "    print('KNN, 5 neighbors')\n",
    "    C = confusion_matrix(Ytest, predicted_knn)\n",
    "    acc, pr, rc, sp = getcalcCM(C, len(Ytest))\n",
    "    print('  accuracy:{0:.2f}%, precision : {1:.2f}%, recall : {2:.2f}%'.format(acc*100, pr*100, rc*100))\n",
    "    \n",
    "    mlpcla = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(40,20), random_state=1)\n",
    "    mlpcla.fit(Xtrain, Ytrain)\n",
    "    predicted_mlp = mlpcla.predict(Xtest)\n",
    "    print('MLP: 2 layers (40,20)')\n",
    "    C = confusion_matrix(Ytest, predicted_mlp)\n",
    "    acc, pr, rc, sp = getcalcCM(C, len(Ytest))\n",
    "    print('  accuracy:{0:.2f}%, precision : {1:.2f}%, recall : {2:.2f}%'.format(acc*100, pr*100, rc*100))\n",
    "    return 'ended function'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART (decision tree)\n",
      "  accuracy:72.71%, precision : 81.94%, recall : 79.92%\n",
      "KNN, 5 neighbors\n",
      "  accuracy:72.49%, precision : 77.10%, recall : 88.19%\n",
      "MLP: 2 layers (40,20)\n",
      "  accuracy:72.39%, precision : 72.39%, recall : 100.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ended function'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMPARING THESE THREE CLASSIFIERS\n",
    "CART_KNN_MLP(Xcr_train, Xcr_test, Ycr_train, Ycr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I think, for predicting the clients suitable to be receive a credit approval,  we need a higher **precision** rate, because even if we reject people who maybe would in reality be good credit payers,\n",
    "we do not want to risk in lending money to any single person that is likely not going to pay. A small set of clients with unpaid debts can potentially sum up big amounts of money, so we prefer to be highly selective. (Let's suppose a recently founded ethical bank is involved in this exercice, on the other hand a huge corp that can afford risks would prefer recall to be maximised).\n",
    "\n",
    "In an opposite exemple, to detect a disease, we'd prefere to have a high recall even if \n",
    "precision is low, as we wont want to take the risk of letting people die because under-diagnosis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.3 NORMALIZED DATA :  running again CART, KNN and MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "Xnorm_train  = scaler.fit_transform(Xcr_train)\n",
    "# learn scale params first, so they can be used later when scaling 'test' data\n",
    "Xnorm_test = scaler.transform(Xcr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART (decision tree)\n",
      "  accuracy:72.71%, precision : 81.82%, recall : 80.11%\n",
      "KNN, 5 neighbors\n",
      "  accuracy:75.27%, precision : 81.06%, recall : 85.92%\n",
      "MLP: 2 layers (40,20)\n",
      "  accuracy:72.30%, precision : 81.84%, recall : 79.36%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ended function'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CART_KNN_MLP(Xnorm_train, Xnorm_test, Ycr_train, Ycr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.4 Adding new variables from PCA\n",
    "These variables are linear combinations of original variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2187, 16)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca.fit(Xnorm_train) # here training set only\n",
    "Xpca_train = pca.transform(Xnorm_train) \n",
    "Xpca_train = np.concatenate((Xpca_train,Xnorm_train), axis=1)\n",
    "Xpca_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2188, 16)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xpca_test = pca.transform(Xnorm_test)\n",
    "Xpca_test = np.concatenate((Xpca_test,Xnorm_test), axis=1)\n",
    "Xpca_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART (decision tree)\n",
      "  accuracy:72.71%, precision : 81.82%, recall : 80.11%\n",
      "KNN, 5 neighbors\n",
      "  accuracy:75.27%, precision : 81.06%, recall : 85.92%\n",
      "MLP: 2 layers (40,20)\n",
      "  accuracy:72.30%, precision : 81.84%, recall : 79.36%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ended function'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CART_KNN_MLP(Xnorm_train, Xnorm_test, Ycr_train, Ycr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART (decision tree)\n",
      "  accuracy:71.66%, precision : 82.01%, recall : 77.97%\n",
      "KNN, 5 neighbors\n",
      "  accuracy:75.64%, precision : 81.04%, recall : 86.62%\n",
      "MLP: 2 layers (40,20)\n",
      "  accuracy:72.67%, precision : 82.01%, recall : 79.73%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ended function'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CART_KNN_MLP(Xpca_train, Xpca_test, Ycr_train, Ycr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The worst accuracy comes from CART prediction, indeed worsen when scaling the data. Tree-based classifiers often encounter this problems, as correlation between variables is not taken in account by the algorithm:\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>NOTE:</b>  TREES DO NOT CONSIDER CORRELATION BETWEEN VARIABLES, IT TREATS EACH VARIABLE DIFFERENTLY FROM THE OTHERS IN ORDER TO CLASSIFY PERTINENT ONES\n",
    "</div>\n",
    "\n",
    "Best accuracy is achieved by KNN both with scaling and scaling + 'PCA derived variables'. Very similar precision was obtained for KNN and MLP:  accuracy was ~2% higher for KNN, but precision 1% higher for MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.5 Pick out variables : first approach with Random Forest (not optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_vars(Xtrain_scale, Y1,  nom_cols):\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(Xtrain_scale, Y1)\n",
    "    importances=clf.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in clf.estimators_],axis=0)\n",
    "    sorted_idx = np.argsort(importances)[::-1]\n",
    "    features = nom_cols\n",
    "    print(features[sorted_idx])\n",
    "    padding = np.arange(Xtrain_scale.size/len(Xtrain_scale)) + 0.5\n",
    "    plt.barh(padding, importances[sorted_idx],xerr=std[sorted_idx], align='center', color=\"salmon\")\n",
    "    plt.yticks(padding, features[sorted_idx])\n",
    "    plt.xlabel(\"Relative Importance\")\n",
    "    plt.title(\"Variable Importance\")\n",
    "    plt.show()\n",
    "    return [(i,j) for i,j in zip(features[sorted_idx], sorted_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Income' 'Seniority' 'Amount' 'Price' 'Age' 'Assets' 'Expenses' 'Records'\n",
      " 'Time' 'Job' 'Debt' 'Home' 'Marital']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "varsimpor_l = important_vars(Xnorm_train, Ycr_train, labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List ordered with 'Income' being the most important (located at column 8 in matrix):\n",
      "\n",
      "[('Income', 8), ('Seniority', 0), ('Amount', 11), ('Price', 12), ('Age', 3), ('Assets', 9), ('Expenses', 7), ('Records', 5), ('Time', 2), ('Job', 6), ('Debt', 10), ('Home', 1), ('Marital', 4)]\n"
     ]
    }
   ],
   "source": [
    "print(\"List ordered with 'Income' being the most important (located at column 8 in matrix):\")\n",
    "print()\n",
    "print([t for t in varsimpor_l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzXklEQVR4nO3dd3xW9fn/8debQAgr7D2jggxFRgDRWq2jal11tGJVihPraGtbW7ut/XZ825+1rq+zrjpQ0Vpqbd17JYBsZAYkzEAgCSMh4/r9cU7wJtyBOyF3Tsb1fDzuR+6zr/vk3Pd1zudzzucjM8M555yrqkXUATjnnGuYPEE455yLyxOEc865uDxBOOeci8sThHPOubg8QTjnnIvLE0QEJJmkw2q57HGSltR1TNVsa5Wkk2ux3AmScpMRU3MkqY2kf0kqkPRcPW63wR9r9aUm+0LSFEnv72f625KurLvokscTxH6EB+0uSdtjXnfXcwx7JRMze8/MDq/PGA5WuB8HRR1HI3YB0BPoambfSNZGmsKxlizNdV+0jDqARuAsM3s96iBc3ZDU0szKoo6jhgYCSxth3E1CIz1m6oRfQdSCpNaStkk6ImZc9/Bqo0c4fJWk5ZLyJc2Q1Keade11uRl7eSrp3XD03PDq5cKqxTeShoXr2CZpoaSzY6Y9KukeSf+WVCTpE0mH7udzXSpptaQtkn5eZVoLSTdLWhFOf1ZSlxruOiSdIelTSYWS1ki6pcr0L0n6MPw8ayRNCce3kXRbGF+BpPfDcfsUZ8UWV0i6RdJ0SU9IKgSmSBov6aNwG+sl3S0pNWb5EZJeC/93GyX9TFIvSTsldY2Zb4ykPEmt4nzOaveXpEHh2fq3JX0uaXPV/R2znt8AvwIuDI+BK8J1/yLcF5skPS6pYyLrlpQSfp4V4TExS1L/xnKsSUoL/5dbwjiyJfWMs/6fSJpeZdwdku4M318maXEY60pJU2PmO0FSbriODcAjcfZFZXxFkhZJOnffEHR3eKx+Jumk/eyLy8NYtkp6RdLAyhVIuj38HxdKmq+Y35x6YWb+quYFrAJOrmbaw8DvYoavA/4bvj8R2AyMAVoDdwHvxsxrwGHh+7eBK2OmTQHejzdvOHwCkBu+bwUsB34GpIbbLQIOD6c/CmwBxhNcLT4JTKvm8wwHtgNfDmP+C1BW+fmB7wEfA/3C6fcDT1ezrj0xVjPtSIKTk5HARuDr4bSBYfwXhZ+tKzAqnHZPuK/6AinAMWEc+2wr9v8G3AKUAl8Pt9kGGAscHe6TQcBi4Pvh/B2A9cAPgbRweEI47WXgOzHbuR24q5rPWe3+CrdpwINhPEcBJcCwatZ1C/BEzPDl4f/9EKA98ALw90TWDdwEzAcOBxRO79pYjjVgKvAvoG14HIwF0uNsYyCwE+gQDqeE/9ejw+EzgEPDfXB8OO+YmM9dBvxvuP02VDnOgG8AfQiOqQuBHUDvmO9wGXBjuN8uBAqALlW/88A54X4dFu63XwAfhtNOBWYBncI4h1Vuo95+A+tzY43tRfBDsx3YFvO6Kpx2MrAiZt4PgMnh+78Bf4qZ1p7gR2pQOFxXCeI4YAPQImb608At4ftHgYdipn0N+Kyaz/orYr7QQDtgN198aRcDJ8VM7x1+ppZx1rXXl+kA+/ivwO3h+58C/4gzTwtgF3BUItti3wTx7gFi+H7ldgmS06fVzHch8EH4PiXc9+Ormbfa/cUXP+L9YqZnAZOqWdct7J0g3gCujRk+PNF1A0uAc6rZToM/1giS44fAyASOrff54jt5CjHf1zjzvgh8L+Zz7wbSEj2mgTmV+5XgO7wOUJX/waXh+7f5IkH8B7iiyrG+kyDBnQgsJTiZabG/z5qslxcxHdjXzaxTzOvBcPxbQFtJExRUwI4C/hFO6wOsrlyBmW0nOLvqW8ex9QHWmFlFzLjVVbazIeb9ToJkVe26KgfMbAdBzJUGAv8IL+u3EXyJywkqTxMW7q+3wqKZAuAaoFs4uT+wIs5i3QjO5uNNS8Sa2AFJQyS9JGmDgmKn3ycQA8A/geGSMgh+cArMLKuaeRPZX4n+b6ra6/gK37dMcN37+3wH2mZDONb+DrwCTJO0TtKfFKeIL/QUQcIH+FY4DICk0yV9rKAYcRtBQusWs2yemRVXs14kTZY0JybGI6osv9bCX/zQ6vBzVzUQuCNmPfkEVwt9zexN4G6Cq+dNkh6QlF5dTMngCaKWzKwceJbgALwIeMnMisLJ6wj+8QBIakdQXLI2zqp2EFwuV+pVgzDWAf0lxf4fB1SznQNZT/DjAYCktgQxV1oDnF4lWaaZWU239RQwA+hvZh2B+wi+EJXbiFduvRkormbaXvtPUgrQvco8VmX4XuAzYLCZpRMUm8TGcEi8wMMfjGeBS4BLCX6sqlNX+yuevY4vgv95GUFx3YFUt48T2Wbkx5qZlZrZb8xsOEEx45nA5Gq28xxwgqR+wLmECUJSa+B54P8BPc2sE0HxoWKWrXrM7BHWETwIXE9QPNcJWFBl+b6SYocHEOzDqtYAU6t81jZm9iGAmd1pZmMJiuWGEBQR1htPEAfnKYJih4uJOTshuPS+TNKo8GD8PfCJma2Ks445wHmS2iq4xfCKKtM3Us0PFvAJwZnajyW1knQCcBYwrRafZTpwpoJK4lTgVvY+Pu4DfhdTgdZd0jm12E4HIN/MiiWNJzizq/QkcLKkb0pqKamrpFHhWevDwF8k9VFQ0Tox3LdLgTQFld+tCMpwWycQQyGwXdJQ4Dsx014Cekv6voKbETpImhAz/XGCIoSz2X+CqKv9Fc/TwI2SMiS1Jzi+nrHE7rR5CPitpMFhJehIfVHx3uCPNUlfkXRkeCJQSFD0VEEcZpZHUJzzCJBjZovDSakEx0geUCbpdOCrNYi/HUECyQtjuozgCiJWD+C74b76BkH9wctx1nUf8FNJI8J1dQznR9K48Iq7FcGJUHF1nzVZPEEc2L+093MQlcVImNknBP+4PgRliZXjXwd+SXCWsp7gjG1SNeu/naC8cyPwGMGPZKxbgMfCS9Bvxk4ws90EX9LTCc6y/4+gzPWzmn5IM1tIUNH+VBjzViD27qA7CM78X5VURFCJOKHqehJwLXBruI5fEZyRV8bwOcGl/g8JLrXnEFSiAvyIoHI1O5z2vwTlsgXhOh8iOJvdUSXueH5EkJiKCM4En4mJoYig+OgsgiKTZcBXYqZ/QPAlnW1mscU8VdXV/ornYYLk9C6QQ/DDcUOCy/6FYJ+/SvAD+zeCSlhoHMdaL4IEU0hQ9PQO+0/UTxHUF+45gQv/x98l2A9bCY6FGTWIfxFwG/ARwff2SII6yFifAIMJ9tXvgAvMbEuVeTCzfxAcy9PC4s4FBPsYIJ3g+NxKUES1BfhzonHWBe1dTOacOxBJbwJPmdlDUcfiXDJ5gnCuBiSNA14jqEMpOtD8zjVmXsTkXIIkPQa8TvDMhCcH1+T5FYRzzrm4/ArCOedcXE2msb5u3brZoEGDog7DOecalVmzZm02s6rPDgFNKEEMGjSImTNnRh2Gc841KpKqvV3bi5icc87F5QnCOedcXJ4gnHPOxZXUBCHpNElLFHScc3Oc6beHLSLOkbQ0bM2wctoASa8q6EhjkbzLSuecq1dJq6QOG9O6h6Bdm1wgW9KMsB0TAMzsxpj5bwBGx6zicYIOeV4LGySr10aqnHOuuUvmFcR4YLmZrQwb+ppG0HtSdS4iaKUSScMJOqJ5DYL+FMxsZxJjdc45V0UyE0Rf9u6oJZdqOswJm/XNAN4MRw0Btkl6QUH/xX8Or0iqLne1pJmSZubl5dVx+M4517w1lErqScD0sBMeCIq+jiNolnkcQRv1U6ouZGYPmFmmmWV27x73OQ/nnDugpRuLmJb1OSVl5QeeuRlJZoJYS0yvUQQdkFfX+9QkwuKlUC4wJyyeKiPoL3ZMMoJ0zjVvWTn5nP9/H3LzC/M5+S/v8NK8dXgbdYFkJohsYHDY61UqQRLYp1OOsEevzgSdb8Qu20lS5WXBicCiqss659zBePOzjVz6t0/ont6aOy8aTbvUllz/1Kecd++HzFqdH3V4kUtaggjP/K8n6GB8MfCsmS2UdKuks2NmnQRMi+3gOyxq+hHwhqT5BH29PpisWJ1zzc8/56zl6sdnMaRnB56bOpGzj+rDv797HH+6YCRrt+7i/Hs/4tonZ7F6y46oQ41Mk2nuOzMz07wtJtcU5BWV0ELQuW0qLVrowAu4Gnv8o1X8esZCJmR04cHJmXRIa7XX9J27y3jw3Rzuf3cFpeUVTJ44iBtOPIxObVMjijh5JM0ys8y40zxBONdwPDtzDT95fh5mkNJCdGufSrf2reneoTXdw797hjt8MZye1hLJk8mBmBl3vbmcv7y2lJOH9eTub40mrdU+N0jusamwmL+8tpRnZ66hQ1orbjjxMC6dOJDWLatfprHxBOFcI/DmZxu56vFZTMjowinDe5JXVMLm7SXkFZWQF/7dsn03ZRX7fmdTW7aoNoF0b58a/k2jW4dU2qY2mUaca6SiwvjtvxfxyAerOH9MP/73/CNpmZJYKfvi9YX8/uXFvLdsMwO6tOXm04dy+hG9mkRS9gThXAP36edbuejBjzmsR3umXT2R9q3j/4hXVBjbdpUGSSNOAtkzXFRC/s7dxPt6D+3VganHH8KZI/vQKsEfyMaurLyCHz8/jxdmr+XyYzP4xRnDalV8987SPH7/78Us2VjE2IGd+fkZwxgzoHMSIq4/niCca8BW5G3ngns/pENaK57/zjF079C6TtZbVl5B/o7dbAoTyOaiEjYWFvPPOetYtmk7fTu14YovZTBpfP8mfVVRXFrO9U99yuuLN/LDU4Zw/YmHHdSZf3mF8dzMNdz22lLyiko4c2RvfnLaUPp3aVuHUdcfTxDONVCbCos5794P2bW7nOe/cwyDurVL+jYrKoy3lmzivndWkL1qK53atmLyxEFMOWYQXdo1rUrYouJSrnp8Jh+vzOfWc0YweeKgOlv3jpIy7n93JQ+8u4KKCphy7CCuO+EwOrZtdeCFGxBPEM41QIXFpVx4/8es3rKDaVcfzch+neo9hlmr87n37ZW8vngjaa1acGFmf6487pBGezYca8v2EqY8ks3i9YXc9s2jOGdU3JZ+DtqGgmJue3UJ02fn0rFNK7530mAunjCQ1JaNo/jOE4RzDUxJWTmXPZJNVk4+f5syjuOHRNtUzPJNRdz/zkpenLOWCoMzjuzN1OMPYUSfjpHGVVvrtu3ikr99wtqtu7j3kjGcOLRn0re5aF1Qkf3+8s0M6tqWm08fxqkjejb4imxPEM41IBUVxnenfcpL89bzl28exXlj+kUd0h7rC3bxyAerePLj1ezYXc6Xh3Tnmi8fwsRDuzb4H7pKK/K2c+lDn1BUXMbfpoxjfEaXetu2mfH2kjx+//Jilm3azvhBXfjZGcMY1b9TvcVQU54gnGsgzIxbXwputfzp6UOZevyhUYcUV8GuUp74eDWPfLCKzdtLOKpfR6YefyinjuhFSgN+eG/B2gImP5xFC8Gjl43niL7RXAGVlVfwzMw13P7aUjZv380ZI3szvHd60rbXMz2NC8bW7kTDE4RzDcT976zgD//5jMuPzeCXZw5r8GflxaXlvDB7LQ+8u4JVW3aS0a0dVx13COeN6bvfB8yi8PHKLVz52Ew6tmnFE1dOIKMeKvwPZHtJGfe/s4KH3sthV2nyWood1b8TL153bK2W9QThXAPwwuxcfvDsXM4c2Zs7J41uVM1olFcYryzcwH3vrGBebgHd2rfmsmMHccnRA+nYJvq7dl5btJHrnprNgC5t+fsV4+ndsU3UIe2lrLyC8iT+1grVulLcE4RzEXtnaR5XPJrN+IwuPHLZuEbbVIOZ8dHKLdz3zkreXZpH+9Yt+daEAVx+bAa9OqZFEtMLs3O5afo8juiTziOXjW9yt+ommycI5yI0L3cbkx74mIFd2/Hs1KP3aRiusVq4roD731nJS/PWkdJCfH1UX6487hCG9Gxfb0VnD7+fw60vLeKYQ7vywOTMap9Ad9XzBOFcRFZt3sH5935Im9QUXvjOMfRIj+YsO5nW5O/kofdW8szMNRSXVpCe1pJhvdMZ3ic9+Ns7ncE929fpVZOZ8dfXl3HHG8s4dURP7pi0/0b3XPU8QTgXgbyiEs6/90O2l5Qx/ZqJHNK9fdQhJdWW7SX8d+EGFq0rZNH6Qj5bX7SnYrZlC3FYj/Z7Esaw3ukM692Bru1r3qxIRUVwJ9ijH67iG2P78YfzEm90z+1rfwnCr8ecS4LtJWVc9mgWeUUlPHXVhCafHAC6tm/NxRMG7hkurzBWb9nB4vVFLFpfwOL1RXy0Ygv/+PSLnod7prfekzAqrzgGdW1X7a20peUV/Hj6PP7x6Vqu/FIGPz+j4d8J1ph5gnCuju0uq+A7T8xi8foiHpqcyehG3tpnbaW0EId0b88h3dtzxsjee8bn79jN4vWFLF5fuOdq471lm/c0Y96mVQqH9+oQU0TVgaG90klpIa57cjZvfLaJm049nGtPONSTQ5J5gnCuDlVUGD+ePpf3lm3mTxeM5CtDe0QdUoPTpV0qxx7WjWMP67ZnXElZOcs3bWfRusI9Vxz/nreepz75HAAJ0tNaUVhcym+/fgSXHj2wutW7OuQJwrk69Mf/fsaLc9Zx06mH883M/lGH02i0bpnCiD4d92r7ycxYV1DM4vAqY/mm7XztyN6cdkSvCCNtXjxBOFdHHnpvJQ+8u5LJEwdy7QkNswmNxkQSfTu1oW+nNpw8PPmN7bl9edW/c3Vgxtx1/M+/F3P6Eb349VkjvGzcNQmeIJw7SB8s38wPn53D+Iwu3H7hqAbdmJ1zNeEJwrmDsGBtAVP/PotDurXnwcmZ/rCWa1I8QThXS2vydzLlkWzS01ry2OXjG0Sjdc7VJU8QztXClu0lTH44i9LyCh6/YnxkDdU5l0yeIJyroR0lZVz+aDbrtu3i4SmZHNajQ9QhOZcUniCcqwEz48Zn5jB/bQF3f2sMYwfWX3eWztU3TxDO1cAD767k1UUb+dnXhnGK35vvmjhPEM4l6JOVW/jTK0s448jeXPGljKjDcS7pPEE4l4BNhcVc//SnDOzSlj+ef6Q/COeaBW9qw7kDKCuv4PqnP2V7cRlPXDGhyfQI59yBeIJw7gD+/OoSsnLyuf3Cozi8l9+x5JoPL2Jybj9eXbiB+99ZycUTBnDu6H5Rh+NcvfIE4Vw1Vm/ZwQ+fm8vIfh351VnDow7HuXqX1AQh6TRJSyQtl3RznOm3S5oTvpZK2lZlerqkXEl3JzNO56oqLi3nmidm00Linm+NoXVLb2PJNT9Jq4OQlALcA5wC5ALZkmaY2aLKeczsxpj5bwBGV1nNb4F3kxWjc9X55YsLWLy+kEemjKN/l7ZRh+NcJJJ5BTEeWG5mK81sNzANOGc/818EPF05IGks0BN4NYkxOrePZ7I/57lZudxw4mHeZahr1pKZIPoCa2KGc8Nx+5A0EMgA3gyHWwC3AT9KYnzO7WPB2gJ++c+FfOmwbnz/5CFRh+NcpBpKJfUkYLqZlYfD1wIvm1nu/haSdLWkmZJm5uXlJT1I17QV7Crl2idn07VdKndM8o5/nEvmcxBrgdhe2/uF4+KZBFwXMzwROE7StUB7IFXSdjPbq6LbzB4AHgDIzMy0ugrcNT8VFcYPn53Lum27eGbqRLq2bx11SM5FLpkJIhsYLCmDIDFMAr5VdSZJQ4HOwEeV48zs4pjpU4DMqsnBubp0/7sreX3xRn591nDGDuwcdTjONQhJK2IyszLgeuAVYDHwrJktlHSrpLNjZp0ETDMzvwJwkfhoxRb+/MpnnDGyN1OOGRR1OM41GGoqv8uZmZk2c+bMqMNwjcymwmK+duf7dGzTkn9e/yXat/bWZ1zzImmWmWXGm+bfBtdslZZXcP1Tn7KjpIynrprgycG5Kvwb4ZqtP7+yhKxV+dwxaRRDenojfM5V1VBuc3WuXv13wQYeeHcllx49kHNGxX08x7lmzxOEa3ZyNu/gpufmclT/TvzizGFRh+Ncg+UJwjUru3aX850nZtEyRfzfxd4In3P743UQrtkwM37x4gKWbCzi0cvG07dTm6hDcq5B8ysI12xMy17D87Nz+e6Jgzl+SPeow3GuwfME4ZqFBWsL+PWMhRw3uBvfPWlw1OE41yh4gnCRqa+HNAt2lnLNE7Po1i6VOyaN9kb4nEuQ10G4erdlewm/fWkRLy/YQEbXdgzr3YHhfdIZ3rsjw3p3qNOG8ioqjB88O4eNhcU8O3UiXdql1tm6nWvqPEG4emNm/Gveem6ZsZCi4lLOHd2XLdt380lOPi/OWbdnvp7prRnWO51hvdMZHv7N6NauVmf+976zgjc+28Rvzh7B6AHeCJ9zNeEJwtWLDQXF/OLF+by+eBNH9e/En84fyeG9vnh6eeuO3SxeX8iiyte6Qt5ftpmyiqAYKq1VC4b2CpNGn3SG9+7A0F7ptNtP8xgfrtjMba8u4ayj+jB54sCkf0bnmhpvrM8llZkxLXsNv//3YkorKvjRVw/nsmMzEroaKCkrZ/mm7SxeX8SidYV7EkjBrlIAJBjYpS3D+6QzrFeQOIb1Tqd3xzQ2FpZw5l3v0altKv+87tj9JhLnmjNvrM9FYtXmHfz0hfl8tHILxxzalT+cdyQDu7ZLePnWLVMY0acjI/p0hLHBODNjfUExi9YFyWLx+kIWrivk5fkb9izXqW0r0lqmsHN3OdOuHuPJwbla8m+Oq3PlFcbD7+dw22tLaNWiBX8870guHNcf6eDvHpJEn05t6NOpDScP77ln/PaSMj5b/8VVxrKN27nyuBEc1sMb4XOutjxBuDq1ZEMRP54+l7m5BZw8rCf/8/Uj6NUxLenbbd+6JZmDupA5qEvSt+Vcc+EJwtWJ3WUV3PPWcv7v7eWkp7XirotGc+bI3nVy1eCci4YnCHfQ5qzZxo+nz2Xpxu2cO7ovvzxzuD9v4FwT4AnC1dqu3eXc9uoSHv4gh57paTwyZRxfGdoj6rCcc3XEE4SrlQ+Xb+bmF+bzef5OLjl6AD85bSgd0lpFHZZzrg55gnA1UrCrlD+8vJhp2WvI6NaOZ64+mgmHdI06LOdcEniCcAl7bdFGfvHifPKKSph6/CHcePIQ0lp5hzvONVWeINwBbd5ewi0zFvLSvPUM7dWBBydnMrJfp6jDcs4lmScIVy0z459z1vGbfy1kR0k5P/rqEKYefyitUryVeOeaA08Qbh+7dpfzysINPJ31OZ/k5DNmQCf+dMFIfyrZuWbGE4QDgquFrJx8np+dy8vzN7C9pIx+ndtwy1nDuXTiIO9kx7lmyBNEM/f5lp08PzuXFz7NZU3+LtqlpvC1I3tz/th+jB/UhRaeGJxrtjxBNENFxaW8PH89z89aS9aqfCQ49tBu/OCUIZw6ohdtU/2wcM55gmg2yiuMD5Zv5vnZubyycAPFpRUc0r0dN516OOeO7kufTm2iDtE518B4gmjilm8qYvqstbz46Vo2FBbTsU0rLhjbj/PH9GNU/07emJ5zrlqeIJqgrTt2869563h+Vi5zcwtIaSFOGNKdX501nJOG9aB1S3+4zTl3YJ4gmojS8greXpLH87NyeeOzjZSWG0N7deAXZwzjnFF96d6hddQhOucamQMmCElnAf82s4p6iMfV0MJ1BUyflcuMOevYsmM33dqnMnniIM4f04/hfdKjDs8514glcgVxIfBXSc8DD5vZZ0mOySWgvML4038/4/53V5Ka0oKTh/fg/DH9+PKQ7v6ks3OuThwwQZjZJZLSgYuARyUZ8AjwtJkVJTtAt6/tJWV8f9qnvL54ExdPGMBNpx5Op7beQY9zrm4ldKppZoXAdGAa0Bs4F5gt6Yb9LSfpNElLJC2XdHOc6bdLmhO+lkraFo4fJekjSQslzZN0YU0/WFOVu3UnF9z7IW8tyePWc0bwu3OP9OTgnEuKROogzgYuAw4DHgfGm9kmSW2BRcBd1SyXAtwDnALkAtmSZpjZosp5zOzGmPlvAEaHgzuByWa2TFIfYJakV8xsWy0+Y5Mxa3U+U/8+i5KyCh6ZMo4vD+kedUjOuSYskTqI84Hbzezd2JFmtlPSFftZbjyw3MxWAkiaBpxDkFTiuQj4dbjupTHbWSdpE9Ad2JZAvE3SC7Nzufn5+fTplMa0q8dxWI/2UYfknGviEkkQtwDrKwcktQF6mtkqM3tjP8v1BdbEDOcCE+LNKGkgkAG8GWfaeCAVWBFn2tXA1QADBgw40OdolCoqjD+/uoR7317BxEO6cu8lY7xIyTlXLxKpg3gOiL3FtTwcV5cmAdPNrDx2pKTewN+By+LdZmtmD5hZpplldu/e9IpbdpSUcc0Ts7j37RVcNH4Aj18x3pODc67eJHIF0dLMdlcOmNluSYn8Sq0F+scM9wvHxTMJuC52RHjn1L+Bn5vZxwlsr0lZu20XVz42kyUbCvn1WcOZcswgbxbDOVevErmCyAsrqgGQdA6wOYHlsoHBkjLChDIJmFF1JklDgc7ARzHjUoF/AI+b2fQEttWkzP58K+fc/QG5+Tt5eMo4Ljs2w5ODc67eJXIFcQ3wpKS7ARHUK0w+0EJmVibpeuAVIIXgIbuFkm4FZppZZbKYBEwzM4tZ/JvAl4GukqaE46aY2ZwE4m3U/jlnLTdNn0ev9DSmXT3Be3FzzkVGe/8u72dGqT2AmW1PakS1lJmZaTNnzow6jFqrqDD+8tpS7n5rORMyunDfJWPp3M7rG5xzySVplpllxpuWUGN9ks4ARgBplUUdZnZrnUXYzO3cXcYPnpnLfxduYNK4/tx6zhGktvTmMpxz0UrkQbn7gLbAV4CHgAuArCTH1WysLwgqoxevL+QXZwzjii95fYNzrmFI5AriGDMbKWmemf1G0m3Af5IdWHMwZ802rnp8Jrt2l/O3b4/jK0N7RB2Sc87tkUiCKA7/7gybvdhC0B6TOwgz5q7jpufm0iO9NU9eOYEhPb0y2jnXsCSSIP4lqRPwZ2A2YMCDyQyqKauoMP76xjLufGMZ4wd14d5LxtC1vXfm45xrePabICS1AN4IG8l7XtJLQJqZFdRHcE3Nrt3l/PC5Obw8fwPfGNuP/zn3CO/+0znXYO03QZhZhaR7CFtZNbMSoKQ+AmtqNhQUc9XjM1mwroCffW0oVx13iFdGO+catESKmN6QdD7wgiX60ITby7zcbVz52Ex2lJTx0ORMThrWM+qQnHPugBJJEFOBHwBlkooJnqY2M/MOjxPw1pJNXPP3WXRr35rnrz2Gob18tznnGodEuhz122sOwl1vLKNPpzY8d81EunlltHOuEUnkQbkvxxtftQMht69du8uZv7aAy7+U4cnBOdfoJFLEdFPM+zSCnuJmAScmJaIm5NM1WyktNyZkdIk6FOecq7FEipjOih2W1B/4a7ICakqyc7YiwdiBniCcc41PbVqEywWG1XUgTVH2qnwO79mBjm1aRR2Kc87VWCJ1EHcRPD0NQUIZRfBEtduP0vIKZq3eyjcz+0UdinPO1UoidRCxnSyUAU+b2QdJiqfJWLiukF2l5Yzz+gfnXCOVSIKYDhSbWTmApBRJbc1sZ3JDa9yyc/IBGD/IE4RzrnFKpA7iDaBNzHAb4PXkhNN0ZK3KZ1DXtvRIT4s6FOecq5VEEkRabDej4fu2yQup8auoMLJX5TPOrx6cc41YIglih6QxlQOSxgK7khdS47c8bzvbdpZ6/YNzrlFLpA7i+8BzktYRtMPUC7gwmUE1dllh/YM/IOeca8wSeVAuW9JQ4PBw1BIzK01uWI1bVk4+PTq0ZkAXL4lzzjVeByxiknQd0M7MFpjZAqC9pGuTH1rjZBbWP2R08f4enHONWiJ1EFeFPcoBYGZbgauSFlEjl7t1F+sLir14yTnX6CWSIFIUcyosKQVITV5IjVtl/YPfweSca+wSqaT+L/CMpPvD4anAf5IXUuOWvSqf9LSWHN7Tu9FwzjVuiSSInwBXA9eEw/MI7mRycWSFzz+0aOH1D865xu2ARUxmVgF8Aqwi6AviRGBxcsNqnPKKSliZt8Off3DONQnVXkFIGgJcFL42A88AmNlX6ie0xmfmKq9/cM41HfsrYvoMeA8408yWA0i6sV6iaqSyVuWT1qoFR/btGHUozjl30PZXxHQesB54S9KDkk4ieJLaVSMrJ5/R/TuT2rI2/TA551zDUu0vmZm9aGaTgKHAWwRNbvSQdK+kr9ZTfI1GUXEpi9cXev2Dc67JSKSSeoeZPRX2Td0P+JTgziYXY9bqrVSY9//gnGs6alQWYmZbzewBMzspWQE1Vtmr8mnZQowZ2CnqUJxzrk4ktbBc0mmSlkhaLunmONNvlzQnfC2VtC1m2rclLQtf305mnHUhKyefEX070jY1kUdLnHOu4Uvar1nYJMc9wClALpAtaYaZLaqcx8xujJn/BmB0+L4L8GsgEzBgVrjs1mTFezCKS8uZu6aAbx8zMOpQnHOuziTzCmI8sNzMVprZbmAacM5+5r8IeDp8fyrwmpnlh0nhNeC0JMZ6UOblFrC7vILxGV2jDsU55+pMMhNEX2BNzHBuOG4fkgYCGcCbNVlW0tWSZkqamZeXVydB10ZWzhYAMgd2jiwG55yraw3lhv1JwHQzK6/JQmGFeaaZZXbv3j1JoR1Y1qqtDOnZns7tvJFb51zTkcwEsRboHzPcLxwXzyS+KF6q6bKRKiuvYPbqrYz35x+cc01MMhNENjBYUoakVIIkMKPqTGF3pp2Bj2JGvwJ8VVJnSZ2Br4bjGpzF64vYXlLm7S8555qcpN3FZGZlkq4n+GFPAR42s4WSbgVmmlllspgETDMzi1k2X9JvCZIMwK1mlp+sWA9GVthAn19BOOeamqTetG9mLwMvVxn3qyrDt1Sz7MPAw0kLro5k5+TTv0sbendsE3UozjlXpxpKJXWjZGZkhx0EOedcU+MJ4iCsyNvBlh27vf0l51yT5AniIGR7/YNzrgnzBHEQsnLy6dY+lYxu7aIOxTnn6pwniIOQlRPUP0jej5JzrunxBFFL67btYu22XV685JxrsjxB1FJl/YPfweSca6o8QdTSJzn5dGjdkmG906MOxTnnksITRC1l5+QzdlBnUlp4/YNzrmnyBFEL+Tt2s2zTdi9ecs41aZ4gasGff3DONQeeIGohOyef1JYtGNmvY9ShOOdc0niCqIXsVfmM6t+J1i1Tog7FOeeSxhNEDe0oKWPBukJvf8k51+R5gqih2Z9vpbzCvP7BOdfkeYKooeycfFoIxgzsHHUozjmXVJ4gauiTnHxG9OlI+9ZJ7WvJOeci5wmiBkrKypmzZps//+CcaxY8QdTAgrUFlJRVeP2Dc65Z8ARRA1k5WwEYN8jrH5xzTZ8niBrIytnCod3b0bV966hDcc65pPMEkaDyCmPm6q2Mz+gadSjOOVcvPEEkaMmGIoqKyxif4cVLzrnmwRNEgrJytgDeQZBzrvnwBJGg7FVb6dupDf06t406FOecqxeeIBJgZmStyve7l5xzzYoniASs2rKTvKISxvnzD865ZsQTRAKyc4IOgiZ4gnDONSOeIBKQtSqfLu1SObR7+6hDcc65euMJIgFZOflkDuyMpKhDcc65euMJ4gA2Fhbzef5Ob3/JOdfseII4gKyw/sEThHOuufEEcQBZOfm0S01heO/0qENxzrl65QniALJX5TNmYGdapviucs41L/6rtx8FO0tZsrGI8d68hnOuGUpqgpB0mqQlkpZLurmaeb4paZGkhZKeihn/p3DcYkl3KoJbiGauzscMf0DOOdcsJa1jZUkpwD3AKUAukC1phpktiplnMPBT4Fgz2yqpRzj+GOBYYGQ46/vA8cDbyYo3nqycfFJTWjCqf6f63KxzzjUIybyCGA8sN7OVZrYbmAacU2Weq4B7zGwrgJltCscbkAakAq2BVsDGJMYaV9aqfEb260haq5T63rRzzkUumQmiL7AmZjg3HBdrCDBE0geSPpZ0GoCZfQS8BawPX6+Y2eKqG5B0taSZkmbm5eXVafC7dpczP7fAi5ecc81W1JXULYHBwAnARcCDkjpJOgwYBvQjSConSjqu6sJm9oCZZZpZZvfu3es0sE8/30pZhfnzD865ZiuZCWIt0D9muF84LlYuMMPMSs0sB1hKkDDOBT42s+1mth34DzAxibHuI2tVPhKMHehNfDvnmqdkJohsYLCkDEmpwCRgRpV5XiS4ekBSN4Iip5XA58DxklpKakVQQb1PEVMyZa/KZ1ivdNLTWtXnZp1zrsFIWoIwszLgeuAVgh/3Z81soaRbJZ0dzvYKsEXSIoI6h5vMbAswHVgBzAfmAnPN7F/JirWq0vIKZq/e5sVLzrlmLWm3uQKY2cvAy1XG/SrmvQE/CF+x85QDU5MZ2/4sWFvArtJyTxDOuWYt6krqBil7VdBA3zh/gto514x5gogjKyefjG7t6N6hddShOOdcZDxBVFFRYWSv2urtLznnmj1PEFUs27Sdgl2l/oCcc67Z8wRRRVbOFgC/gnDONXueIKrIWrWVXulp9O/SJupQnHMuUp4gYpgZ2Tn5jMvoQgStizvnXIPiCSJG7tZdbCgsZvwgb17DOec8QcT4JCd4/mF8RteII3HOueh5goiRnZNPxzatGNyjfdShOOdc5DxBxMhelc+4QZ1p0cLrH5xzzhNEaFNRMSs37/D2l5xzLuQJIjRz1VbA219yzrlKniBCWTn5tGmVwhF9O0YdinPONQieIEJZOfmMGdiJVim+S5xzDjxBAFBYXMriDYVevOScczE8QQCzVm/FzNtfcs65WJ4gCIqXWrYQowf4E9TOOVfJEwTBA3JH9utIm9SUqENxzrkGo9kniOLScublFnjxknPOVdHsE0RhcSmnHdGL44d0jzoU55xrUFpGHUDUenRI486LRkcdhnPONTjN/grCOedcfJ4gnHPOxeUJwjnnXFyeIJxzzsXlCcI551xcniCcc87F5QnCOedcXJ4gnHPOxSUzizqGOiEpD1h9EKvoBmyuo3DqU2ONGzz2qHjs0WiosQ80s7hNSTSZBHGwJM00s8yo46ipxho3eOxR8dij0Rhj9yIm55xzcXmCcM45F5cniC88EHUAtdRY4waPPSoeezQaXexeB+Gccy4uv4JwzjkXlycI55xzcTX7BCHpNElLJC2XdHPU8SRKUn9Jb0laJGmhpO9FHVNNSUqR9Kmkl6KOpSYkdZI0XdJnkhZLmhh1TImQdGN4rCyQ9LSktKhj2h9JD0vaJGlBzLgukl6TtCz82znKGOOpJu4/h8fLPEn/kNQpwhAT1qwThKQU4B7gdGA4cJGk4dFGlbAy4IdmNhw4GriuEcVe6XvA4qiDqIU7gP+a2VDgKBrBZ5DUF/gukGlmRwApwKRoozqgR4HTqoy7GXjDzAYDb4TDDc2j7Bv3a8ARZjYSWAr8tL6Dqo1mnSCA8cByM1tpZruBacA5EceUEDNbb2azw/dFBD9SfaONKnGS+gFnAA9FHUtNSOoIfBn4G4CZ7TazbZEGlbiWQBtJLYG2wLqI49kvM3sXyK8y+hzgsfD9Y8DX6zOmRMSL28xeNbOycPBjoF+9B1YLzT1B9AXWxAzn0oh+ZCtJGgSMBj6JOJSa+CvwY6Ai4jhqKgPIAx4Ji8cektQu6qAOxMzWAv8P+BxYDxSY2avRRlUrPc1sffh+A9AzymBq6XLgP1EHkYjmniAaPUntgeeB75tZYdTxJELSmcAmM5sVdSy10BIYA9xrZqOBHTTMYo69hGX15xAkuD5AO0mXRBvVwbHgHv1GdZ++pJ8TFA8/GXUsiWjuCWIt0D9muF84rlGQ1IogOTxpZi9EHU8NHAucLWkVQbHeiZKeiDakhOUCuWZWebU2nSBhNHQnAzlmlmdmpcALwDERx1QbGyX1Bgj/boo4noRJmgKcCVxsjeQBtOaeILKBwZIyJKUSVNrNiDimhEgSQTn4YjP7S9Tx1ISZ/dTM+pnZIIJ9/qaZNYqzWTPbAKyRdHg46iRgUYQhJepz4GhJbcNj5yQaQeV6HDOAb4fvvw38M8JYEibpNIIi1bPNbGfU8SSqWSeIsNLoeuAVgi/Ls2a2MNqoEnYscCnB2fec8PW1qINqJm4AnpQ0DxgF/D7acA4svOKZDswG5hN89xt00w+SngY+Ag6XlCvpCuCPwCmSlhFcFf0xyhjjqSbuu4EOwGvhd/W+SINMkDe14ZxzLq5mfQXhnHOuep4gnHPOxeUJwjnnXFyeIJxzzsXlCcI551xcniBcgyXJJN0WM/wjSbfU0bq318V6Dnbdkh6RNLXKuK9LSrgpBknXSJp8gHkelXRBnPEnNLbWdF398QThGrIS4DxJ3aLYeNioXbI9zb6tqk4Kxx+QpJZmdp+ZPV7nkblmzxOEa8jKCB7murHqBEmDJL0Ztq//hqQB4fhHJd0r6WNJK8Mz5IfDfhserbKO28P+Ed6Q1D0c97akv0qaCXxP0lhJ70iaJemVymYeqqwnQ9JHkuZL+p8q026SlB3G+Zs4n/ENYGhM8xHtCB4Ae1HSr8JlF0h6IHwCOl6Mt0j6UTjtqnCZuZKel9Q2ZlsnS5opaWnYHlbVz9Eu3FdZYUOE54TjR4Tj5oSfY3D8f5drajxBuIbuHuDisJntWHcBj4Xt6z8J3BkzrTMwkSCxzABuB0YAR0oaFc7TDphpZiOAd4BfxyyfamaZ4TrvAi4ws7HAw8Dv4sR4B0HjfUcStJQKgKSvAoMJmpUfBYyV9OXYBc2snKA9rW+Go84C3g4bXrzbzMaF/Te0IWjHZ68Yzew29vZCuExlPxVXxEwbFMZyBnCf9u0w6OcEzZ6MB74C/DlMWNcAd5jZKCCToD0q1wx4gnANWvhD+ThBZzexJgJPhe//DnwpZtq/wsbQ5gMbzWy+mVUACwl+JCFoZvyZ8P0TVZavHH84cARh8wjAL4jfjv+xfFEk9PeY8V8NX58SNHExlCBhVBVbzBRbvPQVSZ9Img+cSJDkqsZY1RGS3guXubjKMs+aWYWZLQNWhvHE+ipwc/hZ3wbSgAEEzUb8TNJPgIFmtquabbsmpj7KWJ07WH8l+IF9JMH5S8K/FTHvK4erO+Zj25zZEf4VsNDMEulSNF6bNQL+YGb3H2DZD4Heko4iaGF1Unh2/38EPcCtCSvnY8/4d+y7GiDozezrZjZXQeuhJ+wnxqrDAs43syVVxi+W9AnBlcfLkqaa2ZsH+EyuCfArCNfgmVk+8Cx7F5d8yBdn3RcD79VwtS2Ayrt6vgW8H2eeJUB3hX1OS2olaUSc+T6oEkulV4DLFfTZgaS+knpUXTi82nmGoIe0/5hZMV8kg83h8vvcgVSNDsB6BU3BX1xl2jcktZB0KHBI+PlivQLcEFPXMTr8ewiw0szuJGg9dWSCsbhGzhOEayxuA2LvZroBuExBi6qXEvRvXRM7gPEKOpY/Ebi16gxhN7QXAP8raS4wh/h9KHyPoE/w+cT0SBj22PYU8FE4bTrBD3g8TxP0b/10uOw24EFgAcEPd3aCn+uXBD0LfgB8VmXa50AWQW9m14SJKNZvgVbAPEkLw2EI6kcWhEVPRxAU+blmwFtzdc45F5dfQTjnnIvLE4Rzzrm4PEE455yLyxOEc865uDxBOOeci8sThHPOubg8QTjnnIvr/wMFir+TjUI2GQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_accurVsVars(Xtrain_scale, Xtest_scale, Ytrain, Ytest, sorted_idx ):\n",
    "    KNN=KNeighborsClassifier(n_neighbors=5)\n",
    "    scores=np.zeros(Xtrain_scale.shape[1]+1)\n",
    "    # iteratively add variables in importance order!: 8, 0 ... 4 \n",
    "    for f in np.arange(0, Xtrain_scale.shape[1]+1):\n",
    "        X1_f = Xtrain_scale[:,sorted_idx[:f+1]]\n",
    "        X2_f = Xtest_scale[:,sorted_idx[:f+1]]\n",
    "        KNN.fit(X1_f,Ytrain)\n",
    "        YKNN=KNN.predict(X2_f)\n",
    "        scores[f]=np.round(accuracy_score(Ytest,YKNN),3)\n",
    "    plt.plot(scores)\n",
    "    plt.xlabel(\"Nombre de Variables\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Evolution de l'accuracy en fonction des variables\")\n",
    "    return plt.show()\n",
    "\n",
    "plot_accurVsVars(Xnorm_train, Xnorm_test, Ycr_train, Ycr_test, [i[1] for i in varsimpor_l])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows that accuracy achieves its max (0.76) when including first 11 variables \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>BE CAREFUL:</b>these variables have been \"scored\" only by means of KNN \n",
    " arbitrarily set with 5 neighbors, no tuning yet performed.  \n",
    "</div>\n",
    " \n",
    "So lets  choose best parameters first\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.6 EFFICIENT PARAMETER TUNING : GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 13, 'weights': 'distance'}\n",
      "0.7695453643041492\n",
      "  KNN grid accuracy  : 0.7723948811700183\n",
      "  KNN grid precision : 0.8120689655172414\n"
     ]
    }
   ],
   "source": [
    "# KNN (only accuracy to optimize)\n",
    "parknn = {  \n",
    "   'n_neighbors': [5,7,11,13,15],\n",
    "    'weights' : ['uniform', 'distance']\n",
    "} \n",
    "grid_knnAcc = model_selection.GridSearchCV(KNeighborsClassifier(), parknn, cv=5,\n",
    "                                         scoring='accuracy')\n",
    "grid_knnAcc.fit(Xnorm_train, Ycr_train)\n",
    "print(grid_knnAcc.best_params_)\n",
    "print(grid_knnAcc.best_score_) \n",
    "knn_predAccu = grid_knnAcc.predict(Xnorm_test)\n",
    "print(f'  KNN grid accuracy  : {accuracy_score(Ycr_test, knn_predAccu)}')\n",
    "print(f'  KNN grid precision : {precision_score(Ycr_test, knn_predAccu)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 13, 'weights': 'distance'}\n",
      "0.8068875952791092\n",
      "  KNN refit accuracy  : 0.7723948811700183\n",
      "  KNN refit precision : 0.8120689655172414\n"
     ]
    }
   ],
   "source": [
    "## KNN (accuracy and precision to optim): \n",
    "grid_knn = model_selection.GridSearchCV(KNeighborsClassifier(), parknn, cv=5,\n",
    "                                        refit='precision', scoring=['accuracy', 'precision'])\n",
    "grid_knn.fit(Xnorm_train, Ycr_train)\n",
    "print(grid_knn.best_params_)\n",
    "print(grid_knn.best_score_) \n",
    "knn_pred_g = grid_knn.predict(Xnorm_test)\n",
    "print(f'  KNN refit accuracy  : {accuracy_score(Ycr_test, knn_pred_g)}')\n",
    "print(f'  KNN refit precision : {precision_score(Ycr_test, knn_pred_g)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " KNN: no substantial difference between accuracy vs. accuracy+precision+refit when tuning\n",
    " lets see if same happens for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'alpha': 1e-05, 'hidden_layer_sizes': (50, 30), 'max_iter': 200, 'solver': 'sgd'}\n",
      "0.7923910431229951\n",
      "0.7943327239488117\n",
      "0.8214285714285714\n"
     ]
    }
   ],
   "source": [
    "## MLP (only accuracy to optimize):   \n",
    "parmlp = {\n",
    "    'hidden_layer_sizes': [(40,20), (45,23) , (50,30)],\n",
    "    'activation' : ['tanh', 'relu'],\n",
    "    'alpha' : [1e-3, 1e-4, 1e-5],\n",
    "    'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "    'max_iter' : [100,200]\n",
    "}\n",
    "grid_mlpAccu = model_selection.GridSearchCV(MLPClassifier(), parmlp, cv=5, n_jobs=4,\n",
    "                              scoring='accuracy') \n",
    "grid_mlpAccu.fit(Xnorm_train, Ycr_train)\n",
    "print(grid_mlpAccu.best_params_)\n",
    "print(grid_mlpAccu.best_score_)\n",
    "mlp_predAccu = grid_mlpAccu.predict(Xnorm_test)\n",
    "print(accuracy_score(Ycr_test, mlp_predAccu))\n",
    "print(precision_score(Ycr_test, mlp_predAccu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (40, 20), 'max_iter': 100, 'solver': 'adam'}\n",
      "0.839080876410055\n",
      "0.7915904936014625\n",
      "0.8460122699386503\n"
     ]
    }
   ],
   "source": [
    "## MLP (accuracy and precision to optim):   \n",
    "parmlp = {\n",
    "    'hidden_layer_sizes': [(40,20), (45,23) , (50,30)],\n",
    "    'activation' : ['tanh', 'relu'],\n",
    "    'alpha' : [1e-3, 1e-4, 1e-5],\n",
    "    'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "    'max_iter' : [100,200]\n",
    "}\n",
    "grid_mlp = model_selection.GridSearchCV(MLPClassifier(), parmlp, cv=5, n_jobs=4,\n",
    "                              refit='precision', scoring=['accuracy', 'precision']) \n",
    "grid_mlp.fit(Xnorm_train, Ycr_train)\n",
    "print(grid_mlp.best_params_)\n",
    "print(grid_mlp.best_score_)\n",
    "mlp_pred_g = grid_mlp.predict(Xnorm_test)\n",
    "print(accuracy_score(Ycr_test, mlp_pred_g))\n",
    "print(precision_score(Ycr_test, mlp_pred_g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP: optimising only accuracy yields better prediction in terms of accuracy and precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'random_state': 1}\n",
      "0.7576596344942165\n",
      "  CART grid accuracy  :0.7605118829981719\n",
      "  CART grid accuracy  :0.7740434332988625\n"
     ]
    }
   ],
   "source": [
    "# CART\n",
    "parcart = {\n",
    "    'criterion' : ['gini'],\n",
    "    'max_depth' : [3,5,7],\n",
    "    'min_samples_split' : [2,4],\n",
    "    'random_state' : [1]\n",
    "    \n",
    "}\n",
    "grid_cart = model_selection.GridSearchCV(DecisionTreeClassifier(), parcart, cv=5,\n",
    "                                        scoring='accuracy')\n",
    "grid_cart.fit(Xnorm_train, Ycr_train)\n",
    "print(grid_cart.best_params_)\n",
    "print(grid_cart.best_score_) \n",
    "cart_pred_g = grid_cart.predict(Xnorm_test)\n",
    "print(f'  CART grid accuracy  :{accuracy_score(Ycr_test, cart_pred_g)}')\n",
    "print(f'  CART grid accuracy  :{precision_score(Ycr_test, cart_pred_g)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GridSearchCV* made it easier to find best parameters for these three classifiers. We obtained as optimized parameters using the training dataset X and its class vector Y:\n",
    "\n",
    "  - KNN: {'n_neighbors': 13, 'weights': 'distance'}\n",
    "\n",
    "  - MLP:  {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 30), 'max_iter': 100, 'solver': 'adam'}\n",
    "\n",
    "  - CART: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'random_state': 1}\n",
    "\n",
    "*MLP* reported the best accuracy and precision (79,43% and 84,23%, respectively) on Y prediction for normalized X test dataset using optimized parameters. However random re-sampling will be introduced (cross-validation), to add robustness to 'best clasifier' selection at section **'Comparing learning algorithms'**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.7 A ways to 'INDUSTRIALIZE' prediction : Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7102376599634369\n"
     ]
    }
   ],
   "source": [
    "mixfeat = FeatureUnion([('pca', PCA(n_components=3))])\n",
    "             \n",
    "pipeline = Pipeline( [\n",
    "    ('ss', StandardScaler()),\n",
    "    ('combinedf', mixfeat),\n",
    "     ('knn', KNeighborsClassifier(n_neighbors=13, weights='distance'))\n",
    "])\n",
    "pipeline.fit(Xcr_train, Ycr_train)\n",
    "pr = pipeline.predict(Xcr_test)\n",
    "confusion_matrix(Ycr_test, pr)\n",
    "print(accuracy_score(Ycr_test,pr))\n",
    " \n",
    "fileo = open(\"pipeBANK.pkl\", 'wb')\n",
    "pickle.dump(pipeline, fileo)  # save binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07661766, 0.92338234],\n",
       "       [0.53295434, 0.46704566]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HOW TO USE SAVED PIPELINE :  \n",
    "# lets say we have 2 new clients:\n",
    "Xmintest = Xcr_test[8:10,0:]  # \"2 new clients\"\n",
    "ppline=pickle.load(open( \"pipeBANK.pkl\", \"rb\" ) ) \n",
    "ppline.predict_proba(Xmintest)\n",
    "# if I want to predictions for specific variable\n",
    "# ppline.predict_proba(test.values[:,var1])  \n",
    "# \"\"\" END pipeline part \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.8 Comparing learning algorithms (Comparaison de plusieurs algorithmes d’apprentissage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import time\n",
    "clfs = {\n",
    "    'RF': RandomForestClassifier(n_estimators=50, random_state=1),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=13, weights='distance'),\n",
    "    'ADA' : AdaBoostClassifier(n_estimators=50, random_state=1),\n",
    "    'BAG' : BaggingClassifier(n_estimators=50), \n",
    "    'MLP' : MLPClassifier(activation='tanh', alpha=0.001, \n",
    "                          hidden_layer_sizes=(50, 30), max_iter=100, solver='adam'),\n",
    "    'NB' : GaussianNB(),\n",
    "    'CART' : DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=1),\n",
    "    'ID3' : DecisionTreeClassifier(criterion='entropy', random_state=1),\n",
    "    'ST' : DecisionTreeClassifier(max_depth=1, random_state=1) #decisionStump\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function 'run_classifiers' performs cross-validation, the results are stocked in a dictionnary for comparisons that helps to retain the best classifier. It uses 'KFold' which performs re-sampling (no preliminary splitting 'test' and 'train' needed). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifiers(clfs, X, Y):\n",
    "    dico = {'classifier':[],'accuracy_mean':[],'accuracy_sd':[], \n",
    "             'precision_mean':[], 'precision_sd':[],\n",
    "            'AUC':[], 'time_s':[]} #output into dictionnary\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    for clf_id in clfs:\n",
    "        initime = time.time()\n",
    "        clf = clfs[clf_id]\n",
    "        cvAccur = cross_val_score(clf, X, Y, cv=kf, n_jobs=4)\n",
    "        end = time.time()\n",
    "        cvPrecision = cross_val_score(clf, X, Y, cv=kf, scoring='precision', n_jobs=4)\n",
    "        cvAUC = cross_val_score(clf, X, Y, cv=kf, scoring='roc_auc', n_jobs=4)\n",
    "        dico['classifier'].append(clf_id)\n",
    "        dico['accuracy_mean'].append(round(np.mean(cvAccur),3)),\n",
    "        dico['accuracy_sd'].append(round(np.std(cvAccur),3)),\n",
    "        dico['precision_mean'].append(round(np.mean(cvPrecision),3)),\n",
    "        dico['precision_sd'].append(round(np.std(cvPrecision),3))\n",
    "        dico['AUC'].append(round(np.mean(cvAUC),3))\n",
    "        dico['time_s'].append(round((end-initime),3))\n",
    "    return dico\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "XnormALL  = scaler.fit_transform(Xcred)\n",
    "# As function uses 'KFold' splitting data as in previous steps is no longer necessary:\n",
    "dicores = run_classifiers(clfs, XnormALL, Ystatus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_sd</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_sd</th>\n",
       "      <th>AUC</th>\n",
       "      <th>time_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.831</td>\n",
       "      <td>3.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADA</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAG</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.813</td>\n",
       "      <td>1.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CART</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ST</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ID3</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  accuracy_mean  accuracy_sd  precision_mean  precision_sd    AUC  \\\n",
       "4        MLP          0.795        0.009           0.834         0.011  0.831   \n",
       "2        ADA          0.791        0.009           0.823         0.012  0.829   \n",
       "0         RF          0.783        0.005           0.821         0.009  0.818   \n",
       "1        KNN          0.776        0.009           0.812         0.012  0.798   \n",
       "3        BAG          0.774        0.005           0.824         0.007  0.813   \n",
       "5         NB          0.769        0.010           0.847         0.017  0.796   \n",
       "6       CART          0.753        0.011           0.812         0.009  0.748   \n",
       "8         ST          0.727        0.009           0.753         0.017  0.616   \n",
       "7        ID3          0.715        0.006           0.803         0.007  0.645   \n",
       "\n",
       "   time_s  \n",
       "4   3.292  \n",
       "2   0.309  \n",
       "0   0.518  \n",
       "1   0.149  \n",
       "3   1.060  \n",
       "5   0.041  \n",
       "6   0.018  \n",
       "8   0.012  \n",
       "7   0.041  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabres = pd.DataFrame.from_dict(dicores)\n",
    "tabres.sort_values(by=['accuracy_mean', 'precision_mean', 'AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Best classifiers for predicting good payers:</b> MLP exhibits best accuracy, precision \n",
    "    and Area Under the Curve (AUC). \n",
    "</div>\n",
    "ADA, RF and BAG perform very similar, whereas KNN and NB see their AUC diminish (false positive rate increments at the cost of true positive rate reduction). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.9 Use optimal classifier to check variables vs accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accurVsVars(Xtrain_scale, Xtest_scale, Ytrain, Ytest, sorted_idx ):\n",
    "    meth=MLPClassifier(activation='tanh', alpha=0.001, \n",
    "                          hidden_layer_sizes=(50, 30), max_iter=100, \n",
    "                       solver='adam', random_state=1)\n",
    "    scores=np.zeros(Xtrain_scale.shape[1]+1)\n",
    "    for f in np.arange(0, Xtrain_scale.shape[1]+1):\n",
    "        X1_f = Xtrain_scale[:,sorted_idx[:f+1]]\n",
    "        X2_f = Xtest_scale[:,sorted_idx[:f+1]]\n",
    "        meth.fit(X1_f,Ytrain)\n",
    "        Ypred=meth.predict(X2_f)\n",
    "        scores[f]=np.round(accuracy_score(Ytest,Ypred),3)\n",
    "    plt.plot(scores, color=\"orangered\")\n",
    "    plt.xlabel(\"Nombre de Variables\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy vs variables: MLP with optimised params\")\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzQElEQVR4nO3dd5xU1fnH8c+XBcQuCDa6imJD1LVHwYLBWNBo4mLD2H/2FoNJRERNTIyxR8VeKCoqYBRRKVZUVkUFVEREAVFBQQVFBJ7fH+dMGIbZ3dkye2d3n/frNa+d25+ZvXOfOeeeOUdmhnPOOZepUdIBOOecK0yeIJxzzmXlCcI551xWniCcc85l5QnCOedcVp4gnHPOZeUJwiVO0j6SPspx3ZMkvVLO8vGSTq256OoOSYskbV7O8pmSDqzNmNKOPUpSnypue4eky2s4nu6SZtfkPusjTxAZ4gVmgaQ1ko6loTCzl81s66TjyFU8R0zSjhnzn4zzu8fp/pIeLmMfMyX9FC/qX0m6X9I61YnLzNYxsxlx//dLuro6+6uqbK/bzA42sweqsj8zO9PMrqqZ6FxleIJII6kDsA9gwOG1fOzGtXm8QlGHX/c04MTUhKQNgT2BeZXYx2Fmtg6wM1AM/LVGI3SJq8PnN+AJItOJwOvA/cAqxWFJbSU9IWmepG8k3Zq27DRJH0j6QdJUSTvH+SZpy7T1/vetLlXElfQnSV8C90lqLum/8RgL4vM2adu3kHSfpC/i8uFx/mRJh6Wt10TSfEk7Zb7AGOehadON4/F2ltRM0sPx9S2UNFHSxln28SdJwzLm3STp5vj8D2nvxwxJZ6Stl+11r1Lcl9RX0idp7+eRq4egWyV9J+lDSQdkxpi24skxlgWSRktqn9qBpBskfS3pe0nvS9q+rP1kMQg4RlJRnO4NPAksrcQ+ADCzOcAoYLXjx/fyqbTpjyU9ljY9S1LX+NwkbSnpdOA44NJYQnkqbZddJb0X37tHJDXLFpOkRpL+Kumz+B49KGn9uKxDPNbp8VycK+mSuKwn8Of43iyS9G6c/7+qP4Vqwlfj+78wniN7xfmz4vH6pMWS/rlpGT8XCyV9K+llSY3iss0kPR7P508lnZe2jzXjfhZImgrsWt7/JL6+82Js8yVdl3acLSSNjZ+T+ZIGSdogbduZ8fx+D1is8Bkr85yuwvvxm7iPHyTNSb33eWFm/ogPYDpwFrAL8AuwcZxfBLwL3ACsDTQDfhWX/Q6YQzjhBGwJtI/LDNgybf/3A1fH592BZcA/gDWANYENgaOAtYB1gceA4WnbPw08AjQHmgDd4vxLgUfS1usFvF/Ga+wHDEqbPgT4ID4/A3gqHr8ovg/rZdlHe+BHYN2092cusEfaPreI70e3uO7O5bzu7sDstP3/DtiM8AXmGGAxsGlcdlLc/sL4HhwDfAe0iMvHA6emvQ/TgW2AxoRv6K/FZb8G3gI2iHFuk3aMY4H3yjlPxgOnAs8BB8d5bxJKELOB7nFef+DhMvYxEzgwPm8LTAGuyrLe5sDC+F5sBnyWeq/isgVAo8zzjbRzLeOYb8b9tAA+AM4sI76T43u3ObAO8ATwUFzWIR5rCOHzsAOh5HRgWa874/+S+h/+gXDuXA18DtwWz4mDgB+AdbJ8bv4O3BH/900IJX7F9+ctwvndNMY9A/h13O5a4OX4utsCk0k757K8fgPGxfXbEUqMqfi3BHrEWFsBLwE3ZrzPk+Jx1qzEOZ3r+zEX2Cc+b078bOXlmpivHde1B/ArQlJoGac/BC6Mz1NVB42zbDcaOL+ck6y8BLEUaFZOTF2BBfH5psAKoHmW9TaLJ9B6cXoYcGkZ+9wyrrtWnB4E9IvPTwZeA7rk8H69ApwYn/cAPiln3eGp9yjb6yYjQWTZfhLQKz4/CfgCUNryN4ET4vPxaR/kUcApaes1IiSr9sD+hA/9HsQLbCXOlfGEBHE84SLZGZgWl1UmQSwiXPw/A/5DvJhkWXcWoRqqBBgYX29nwgVlZLbzjbITxPFp0/8E7ijjmGOAs9KmtyZ8PhqzMkF0ztjXPWW9blZPEB+nLdsh7m/jtHnfAF2zfG4GACNI+1zF+bsDn2fMuwy4Lz6fAfRMW3Z6BeecZax/FjCmjHWPAN7JeJ9PruAcmsSq53Rl3o/PCV/mVvvyVtMPr2JaqQ/wnJnNj9ODWVnN1Bb4zMyWZdmuLfBJFY85z8yWpCYkrSXpzlis/57wzWSDWI3RFvjWzBZk7sTMvgBeBY6KRd2DCRf+1ZjZdMI3x8MkrUW41zI4Ln6IkPCGxqqDf0pqUkbsgwnVKhC+caf2gaSDJb0eqwAWAr8BWpb1ujNJOlHSpFjcXkioeknffo7FT0r0GSFJZmoP3JS2n28J3zZbm9lY4FbCt7SvJQ2UtF5ZMZXhCUKiOYfw3lXWEWa2gZm1N7OzzOynMtZ7kZBE943PxxNKZt3idGV8mfb8R0LpIJtUaSXlM0JySK9ynJWxPNv/oCxfpT3/CcDMMudli+06QsnmuVgV0zfObw9slvpfx//3n9Pi3SxLvBXJ+vokbSxpaKze+R54mFXPz8xtczmnK/N+HEX4TH0m6UVJe+bwWqrEEwShfhL4PdBN0pcKdeMXAjsqtFSZBbRT9htOswjVKdn8SKiuSdkkY7llTF9M+Ka2u5mtR7ggQLiozQJapNd1ZniA8I32d8AEC/XaZRlCuLj3AqbGpIGZ/WJmV5rZtsBewKGk3YjN8BjQXeEeyZHEBKHQ+utx4F+Eb0AbAM/E11DW6/4fhXsEdxEuuhvG7SdnbN9aUvp0O0KpItMs4Ix4EU491jSz1+LrvdnMdgG2BbYC/lhWXNmY2Y+EUsr/UbUEkatUgtgnPn+RihNEme9xjr4gXHRT2hGqQdIvWm0zlqf+B9U9dpnM7Aczu9jMNid8ublI4R7ULODTjP/1umb2m7jp3CzxVqSs1/c3wmvcIX5Oj2fV8xPS3oMcz+mcmdlEM+sFbEQonT9alf3kwhNEcASwnHCh6Bof2xDqLE8kFOnnAtdKWlvhZu7ecdu7gUsk7aJgy3hCQChGHiupSOHmXbcK4liX8E1hoaQWwBWpBWY2l3Ax+o/CzewmkvZN23Y4oRrifODBCo4zlFCv+X+s+s1/P0k7xBLL94QqhRXZdmBm8wjfZO8jfDA/iIuaEupN5wHLJB0cj5WrtQkfrnkxpj+w+s3bjYDz4nvwO8L/6pks+7oDuEzSdnFf68f1kbSrpN1jCWkxsKSs11qBPxPuBc0sY3mjeL6kHlVpPv0isB+hCmo24bzsSbhn9U4Z23xFqIevqiHAhZI6KjS//RvhPld6KfryWOrdjlDd9UjasTukburWJEmHxs+YCPeelhP+b28CP8Sbw2vGz9z2klI3ox8lnAvN45eac3M43B/j+m0Jn6vU61uXUD34naTWVPzFIpdzOieSmko6TtL6ZvYL4XNalfM2J54ggj6EusrPzezL1INQBXEcIdMfRqi//5xQz3wMgJk9BlxDuND+QLhQt4j7PT9utzDuZ3gFcdxIuGk7n9Ca6tmM5ScQLtofAl8DF6QWxOqJx4GOhKqPMsVkM4FQSngkbdEmhPsX3xOqoV6k/G/Gg4EDSUsyZvYDcB7hA7mAUP00srx4MmKbClwf4/uKUB/7asZqbwCdCO/TNcDRZvZNln09SbgZPjRWBUwmVL8BrEf4VreAUH3wDaH6gvgBnJJjvF+YWZk/3COU1H5Ke1S6OtLMphEuSC/H6e8JdeqvmtnyMja7B9g2VmkMr+wxgXsJ//uXgE8JCTTzovoiobpnDPAvM3suzk+1svpG0ttVOHZ5OgEvEN6PCcB/zGxcfB8OJXy5+5RwbtwNrB+3u5Lwf/6U0LgglxLfCMKN70mEBiL3pO1rZ0KCepqKP2+5nNOVcQIwM57TZxKuLXmhVatyXV0mqR+wlZkdn3Qsrv5S+L3Qp0CTMu7L1XmSDOiUqn5tqOr0jzjcSrFK6hTCtwvnnKs2r2KqBySdRrhJN8rMXko6Hudc/eBVTM4557LyEoRzzrms6s09iJYtW1qHDh2SDsM55+qUt956a76Ztcq2rN4kiA4dOlBaWpp0GM45V6dIKvNX5V7F5JxzLitPEM4557LyBOGccy4rTxDOOeey8gThnHMuK08QzjnnsvIE4ZxzLqt68zsI51w5zGD2NHh3HHyTbWylGlLUBDZqB5t0hE03hw03g0b+PbSu8gThXH319SyYNBYmjQl/56cNMqgqDWZWscy+3Zo0hY3ar0wYm3Rc9bFui/zF4qrNE4Rz9cXCefDeeHgnJoQ5H4f567eCrvuHx04HhAt1vi7KS3+GeZ/D3E/hy0/hyxnx76fw8Vvwfca4Tmutt2rCSE8iG3eAZmtlPYyrHZ4gnKurFn8Pk19emRBmvBvmr7Uu7NANDjsrJIUO29deNU/TNaB1p/AoK+ZUwpg7A76Kz+dMg7dGw88/rbp+i01isojJo9sx0LFKo3W6Kqg33X0XFxeb98Xk6rWlS2DqhJAQ3h0LH74JK5ZDkzVgu71D6aDr/rBVMRTVwe9+ZrDgq5XJI5VIUiWRebNAjaD3n6HkzyEZuWqT9JaZFWdbVgfPIucaiOXLYNpbK+8hTHk1JIlGRbD1rnBM35AQttsLmjZLOtrqk0KJocUmsO2eqy//bj7ccSE8PABefhwuuge22b3242xAvAThXCFZsQKevQdefwreexF+/D7M37wLdI0lhB32hbXXSzbOJL3xNNx0JnwzB468APpcBWuunXRUdVZiJQhJPYGbgCLgbjO7NmN5O+ABYIO4Tl8zeyYuu4wwxvJy4DwzG53PWJ0rCC8PgxtPh822gO4lodqoS3dovlHSkRWO3Q+Bu6bAPX3hiRtgwgi44C7Yaf+kI6t38laCkFQETAN6ALOBiUBvM5uats5A4B0zu13StsAzZtYhPh8C7AZsBrwAbGVmy8s6npcgXL1w4a/g27lw7zQoKko6msL33ovw71Phi+lw8Klw2nWwzgZJR1WnlFeCyGfTht2A6WY2w8yWAkOBXhnrGJAqK68PpH7B0wsYamY/m9mnwPS4P+fqr4/fDvcZDj/Hk0OuunSDO9+D318Ko++FU7eF10YkHVW9kc8E0RqYlTY9O85L1x84XtJs4Bng3Epsi6TTJZVKKp03b15Nxe1cMkbcAmusBb/+Q9KR1C1rrAmn/gNufgPWbwn9j4BrSmDB10lHVucl/Rv43sD9ZtYG+A3wkKScYzKzgWZWbGbFrVplHVLVubph4TwYNwR69PEqkqraqhhuLQ03rV97Ek7dBl54ePVfd7uc5TNBzAHapk23ifPSnQI8CmBmE4BmQMsct3Wu/hh1F/zyM/Q6J+lI6rYmTeG4v8J/3oE2W8E/T4DLDw3djrhKy2eCmAh0ktRRUlOgBBiZsc7nwAEAkrYhJIh5cb0SSWtI6gh0At7MY6zOJWfZL/DU7bDTgdB+26SjqR/abwv/fgX+70Z4dzycvl14j1esSDqyOiVvCcLMlgHnAKOBD4BHzWyKpAGSDo+rXQycJuldQqulkyyYQihZTAWeBc4urwWTc3Xaa8Nh/mw44twKV3WVUFQER54PAyfD1rvDLWfBJd1Dr7YuJ/5DOeeSdtG+IUHc97G3XsoXMxh9H9x5UajKO/FKOOqi/HdJsuRH+GomfP15KCnmyzobwA77VGlT72rDuUL1yaTQ4d7p//LkkE8S9DwZdu0Jt5wNd/8Jxj8CF98LW+xY9f0uXwbzZq/ef1SqE8Jvv6y511CezrvDza/X+G49QTiXpOGppq0nJx1Jw7DhZnDFE+EX67eeA+cUhz6tjv1r9s7/zEILs8yuy1MJYd6skCRSGhVBq7ah59ndDknrurw9NMljf1nN8tPViCcI55Ly3XwYOwgOOgnWbZ50NA2HBPv+LvRrdcdFMPhqeOVxKLksjFexSnfkM2HJ4lW332CjcNHfZg/Yr3faeBabQ6s20LhJIi8rHzxBOJeUUXfHpq1+czoR620Ilz4QLvI3nQH/PDHMX3OdcMHfbEvYuceqgxlt3KFBdQzoCcK5JCxfBk/9Jw7os13S0TRsu/aEu6aGQYtatQ2Jw4dBBTxBOJeM10aE+uuzb0k6EgehVLDlTklHUXCS7mrDuYZpxC2humL3Q5OOxLkyeYJwrrbNeC90U3342d601RU0TxDO1bYRt4QeSL1pqytwniCcq03ffwNjHoYDToD1WiQdjXPl8gThXG169h5YusR7bXV1gicI52rL8mUw8jbYcT/ouEPS0ThXIU8QztWWCU+FTtv8h3GujvAE4VxtGXFz6JNnz8OSjsS5nHiCcK42fPp+GLjmsLPy38W0czXEE4RztWF4bNra89SkI3EuZ54gnMu377+FsQ/D/sd501ZXp3iCcC7fnr0Hfv7Jb067OscThHP5tHw5PHUbdOkGm3dJOhrnKsUThHP59PpT8NVncMR5SUfiXKV5gnAun0bcEsYY2PPwpCNxrtI8QTiXL59OhkljY6+t3rTV1T15TRCSekr6SNJ0SX2zLL9B0qT4mCZpYdqyf0iaHB/H5DNO5/Ji5K3QtBkc7E1bXd2Ut681koqA24AewGxgoqSRZjY1tY6ZXZi2/rnATvH5IcDOQFdgDWC8pFFm9n2+4nWuRv2wAF54KDZt3TDpaJyrknyWIHYDppvZDDNbCgwFepWzfm9gSHy+LfCSmS0zs8XAe0DPPMbqXM0afS/8/KM3bXV1Wj4TRGtgVtr07DhvNZLaAx2BsXHWu0BPSWtJagnsB7TNst3pkkollc6bN69Gg3euypYvhxG3wg77whY7Jh2Nc1VWKDepS4BhZrYcwMyeA54BXiOUKiYAyzM3MrOBZlZsZsWtWrWqzXidK9ubT8NXM71pq6vz8pkg5rDqt/42cV42JaysXgLAzK4xs65m1gMQMC0vUTpX04bfHJq27lVejapzhS+fCWIi0ElSR0lNCUlgZOZKkjoDzQmlhNS8IkkbxuddgC7Ac3mM1bma8dlUeGeM99rq6oW8ncFmtkzSOcBooAi418ymSBoAlJpZKlmUAEPNzNI2bwK8LAnge+B4M1uWr1idqzEjboEma3jTVlcv5PUrjpk9Q7iXkD6vX8Z0/yzbLSG0ZHKu7li0EJ5/MDRtXb9l0tE4V22FcpPaubrv2di09Qhv2urqB08QztWEVK+t2+8DW3RNOhrnaoQnCOdqwpvPwNwZXnpw9YonCOdqwohboGUb2OuIpCNxrsZ4gnCuuj7/AN5+Hg77P2jcJOlonKsxniCcq64Rt8amraclHYlzNcoThHPVsfg7eP4B2K83bODdvbj6xROEc9Ux+j5Ysth7bXX1kicI56pqxYowKNB2e0OnnZOOxrka5wnCuaqaOAq++MR7bXX1licI56pq+M3QsjXsfWTSkTiXF54gnKuKzz+Et56DQ71pq6u/PEE4VxUjb4UmTb1pq6vXPEE4V1mppq3de0PzjZKOxrm88QThXGU9PRB+WuRNW1295wnCucp470W4/y+w68Gw1S5JR+NcXnmCcC5Xs6fBlUfCpltA30FJR+Nc3nmCcC4X382Hvx4CjYrg6qdh3eZJR+Rc3vmo6s5VZOnPoeQwbxb8cyxsunnSETlXKzxBOFceM7jhVJj8Clw2BLbbK+mInKs1XsXkXHkeHgBjHoY+V8F+JUlH41ytymuCkNRT0keSpkvqm2X5DZImxcc0SQvTlv1T0hRJH0i6WZLyGatzqxkzCB7qDz36wLF/SToa52pd3qqYJBUBtwE9gNnAREkjzWxqah0zuzBt/XOBneLzvYC9gS5x8StAN2B8vuJ1bhXvvwz/Phm6dIMLBoJ/P3ENUD5LELsB081shpktBYYCvcpZvzcwJD43oBnQFFgDaAJ8lcdYnVtpzvRwU3rjDtDvidClhnMNUD4TRGtgVtr07DhvNZLaAx2BsQBmNgEYB8yNj9Fm9kGW7U6XVCqpdN68eTUcvmuQvv8WLj8kPL/qaVivRbLxOJegQrlJXQIMM7PlAJK2BLYB2hCSyv6S9sncyMwGmlmxmRW3auXDPbpq+mUpDPgtfDUT+g+H1lsmHZFzicpngpgDtE2bbhPnZVPCyuolgCOB181skZktAkYBe+YlSucgNmc9LXSlcdG9sP2vko7IucTlM0FMBDpJ6iipKSEJjMxcSVJnoDkwIW3250A3SY0lNSHcoF6tism5GjP4GnjhQTihPxxwXNLROFcQ8pYgzGwZcA4wmnBxf9TMpkgaIOnwtFVLgKFmZmnzhgGfAO8D7wLvmtlT+YrVNXDjhsADl8MBx8Px/ZKOxrmCoVWvy3VXcXGxlZaWJh2Gq2umvAaX7g9b7wbXPg9N10g6IudqlaS3zKw427JCuUntXO374hPo3wtatYX+T3pycC6DJwjXMP2wIPTOumJF6J11vQ2Tjsi5guOd9bmG55elMOAo+HIGXPsCtNkq6YicK0gVliAkHSbJSxqufjCDm8+Ed8fBhXdDl32Tjsi5gpXLhf8Y4OPYeV7nfAfkXF498g8YfR8cdzn0ODHpaJwraBUmCDM7ntCJ3ifA/ZImxC4u1s17dM7VpJceg3svg/16w4lXJh2NcwUvp6ojM/ue8NuEocCmhF86vx17YHWu8H3wOvzzRNhub7j4Xu+d1bkc5HIP4nBJTxK62m4C7GZmBwM7AhfnNzznasCXM+GKXtCyNVzxJDRtlnREztUJubRiOgq4wcxeSp9pZj9KOiU/YTlXQxYtDL2zLv8l9M66gXfq6FyuckkQ/QldbgMgaU1gYzObaWZj8hWYc9W27Be46ncw52P4+3PQduukI3KuTsnlHsRjwIq06eVxnnOFywxuORveeQEuuAt27J50RM7VObmUIBrHEeEAMLOlsXdW5wrT8uXwyLUw6i7o/Rc4qE/SETlXJ+WSIOZJOtzMRgJI6gXMz29YzlXBlzPhufvC7xzmzYJux0CfAUlH5VydlUuCOBMYJOlWQIRhRP0XRq4wLP0ZJoyAZ++Bt58P83Y5CM64HvY+Ehp5JwDOVVWFCcLMPgH2kLROnF6U96icq8jMKSEpvPAgfP9N6JH1uH7w6z/Axu2Tjs65eiGnzvokHQJsBzRT/IGRmXnZ3dWunxbB+Efg2bvDD98aN4E9e8HBp8JOB0JRUdIROlevVJggJN0BrAXsB9wNHA28mee4nAvM4MM3Qmlh/NCQJNptA6f/Cw44AZpvlHSEztVbuZQg9jKzLpLeM7MrJV0PjMp3YK6B+24+jHkYRt0Nn02BNdaC7sdAz1Nh2z29qwznakEuCWJJ/PujpM2Abwj9MTlXs1asgHfGhCqk14aHcRu23g0uGBhaJK29XtIROteg5JIgnpK0AXAd8DZgwF35DMo1MF/Pgufuh9H3wlczYd0WcMiZ0PMU2LxL0tE512CVmyDiQEFjzGwh8Lik/wLNzOy72gjO1WPLl8GEkaEK6a3RofSw0wFw8t9h7yO8Qz3nCkC5CcLMVki6jTAeBGb2M/BzrjuX1BO4CSgC7jazazOW30C4+Q3hRvhGZraBpP2AG9JW7QyUmNnwXI/tCtiM9+Dfp8C0UthwMyj5c2ieuunmSUfmnEuTSxXTGElHAU+YmeW6Y0lFwG1AD2A2MFHSSDObmlrHzC5MW/9cViaicUDXOL8FMB14LtdjuwK19GcYcg0M/Tus0xz6DoJuv4ciHxrduUKUyyfzDOAiYJmkJYRfU5uZVXTHcDdgupnNAJA0FOgFTC1j/d7AFVnmHw2MMrMfc4jVFaqpE0Kp4fMP4MAT4MwbYL0Nk47KOVeOXH5JXdWhRVsTuuVImQ3snm1FSe2BjsDYLItLgH9XMQaXtJ8Ww/1/geE3Q8s2cPUzsNvBSUflnMtBLj+U2zfb/MwBhKqpBBhmZsszjr0psAMwuozYTgdOB2jXrl0NhuNqxNsvwA2nhZZJh50VbkB7U1Xn6oxcqpj+mPa8GaHq6C1g/wq2mwO0TZtuE+dlUwKcnWX+74EnzeyXbBuZ2UBgIEBxcXHO90dcni1aCHdeHJqttu4E178EO+yTdFTOuUrKpYrpsPRpSW2BG3PY90Sgk6SOhMRQAhybuZKkzkBzYEKWffQGLsvhWK5QvDocbjkLFn4Nx/SF4/vBGmsmHZVzrgqq0nxkNrBNRSuZ2TJJ5xCqh4qAe81siqQBQGlqfAlC4hia2UJKUgdCCeTFKsToatuCr+C2c+Glx2DzHWHAU7DVLklH5ZyrhlzuQdxC+PU0hCFKuxJ+UV0hM3sGeCZjXr+M6f5lbDuTcKPbFTKz0GfS7RfAkkXwh2vgd38MPa065+q0XEoQpWnPlwFDzOzVPMXj6pKvP4cbz4DSZ2HbveCiu0NPq865eiGXBDEMWJJqYSSpSNJa/ruEBmzFCvjv7XBP31CCOOtmOPxsH73NuXoml0/0GCD9LuOawAv5CccVvFkfwSXd4NZzYJs9YeBkOOJcTw7O1UO5lCCapQ8zamaLJK2Vx5hcIVq+DB77FzzUP7RKuuQ+6NHHx2Vwrh7LJUEslrSzmb0NIGkX4Kf8huUKyieT4PpTYPrb8Kuj4JxbocUmSUflnMuzXBLEBcBjkr4g9MO0CXBMPoNyBWLpEhh0FTzyD1i/JVw+DPY5KumonHO1JJcfyk2MP2bbOs76qKxfNrt6xAz69oDJr8BBJ8Hp18N6LZKOyjlXiyq8syjpbGBtM5tsZpOBdSSdlf/QXKJeHR6Swzm3hfsNnhyca3ByaXpyWhxRDgAzWwCclreIXPJWrIAH+0GbreGQ05OOxjmXkFzuQRRJUqorjDgQUNP8huUS9eKjMHMyXDbEB/NxrgHL5dP/LPCIpDvj9BnAqPyF5BK1fBk8dAV02D6M9uaca7BySRB/Ioy5cGacfo/QksnVR2MGwexp0O8J//Gbcw1chVcAM1sBvAHMJIwFsT/wQX7DcolY9gs8fCVsuTPsfUTS0TjnElZmCULSVoTxGHoD84FHAMxsv9oJzdW60ffBl5/C1bf6L6Sdc+VWMX0IvAwcambTASRdWCtRudqX+lHcNnvArj5mtHOu/Cqm3wJzgXGS7pJ0AOGX1K4+euYumD8bTrraSw/OOaCcBGFmw82sBOgMjCN0ubGRpNslHVRL8bnasORHGPo36NINulY01LhzrqHI5Sb1YjMbHMembgO8Q2jZ5OqL/94O334Jfa7y0oNz7n8q1Y7RzBaY2UAzOyBfAbla9uMP8Mi1sMtBsMM+SUfjnCsg3tC9oRtxC3w3P5QenHMujSeIhmzRQnjsOtj9UOi8W9LROOcKjCeIhuyJG0KS6DMg6UiccwUorwlCUk9JH0maLqlvluU3SJoUH9MkLUxb1k7Sc5I+kDRVUod8xtrgfP9NSBC/Ogq23CnpaJxzBShvXXXGXl9vA3oAs4GJkkaa2dTUOmZ2Ydr65wLpV6oHgWvM7HlJ6wAr8hVrg/TYdfDTIjjxyqQjcc4VqHyWIHYDppvZDDNbCgwFepWzfm9gCICkbYHGZvY8gJktMrMf8xhr/rw0DAZdHUZoKxQLvoLht0D33tBhu6Sjcc4VqHx29t8amJU2PRvYPduKktoDHYGxcdZWwEJJT8T5LwB9zWx5xnanE3qapV27djUafI1YsQLuvAjmzQoJ4vjLk44oGHot/LIETrgi6UiccwWsUG5SlwDD0hJAY2Af4BJgV2Bz4KTMjeJvMorNrLhVq1a1FWvuprwakkObrcMIbeOGJB0RzJ8TfhjXow+02SrpaJxzBSyfCWIO0DZtuk2cl00JsXopmg1MitVTy4DhwM75CDKvxg2GNdaEG1+DHfaFf50UkkaShvwNViyHYwukNOOcK1j5TBATgU6SOkpqSkgCIzNXktQZaA5MyNh2A0mpYsH+wNTMbQvasl/gpcdgz16wXgu44gnYqD30PwK++CSZmL76DEbdBQefCpt2TCYG51ydkbcEEb/5nwOMJgww9KiZTZE0QNLhaauWAENTY17HbZcTqpfGSHqf0IvsXfmKNS/efj40Jd2vd5heb0O4+ulwX+Kvh8APC2o/pkFXgRpB77/U/rGdc3WOrJBa11RDcXGxlZaWJh3GSv84Ad58GoZ+CU2arpz/3kvQ90DYbm/42+hVl+XTnOlwSmc4/Gw466baOaZzruBJesvMirMtK5Sb1PXLkh/h1SfDj9AyE0CXfeGie+Hd8XDTGbXX/PXhK0MsJZfVzvGcc3VePpu5NlyvPwVLFsN+x2ZffuDx8MXH8PAAaN0Jev85v/F8NhXGDoKjL4EWm+T3WM65esMTRD6MGwItNg0tl8pyQv9Q7XPfX2DTLaD7MfmL56H+0Gxt+P2l+TuGc67e8SqmmvbDApj4DHQvgaKisteT4OJ7wr2I6/rA1Allr1sdn7wbWlMdeQGs3zI/x3DO1UueIGraK0+EJq77l1G9lK5pM+g/HFq1gSt6wdwZNR/Pg/1g7fXhqItqft/OuXrNE0RNGzcYNtsSOu2S2/rrt4SrnoYVy0Lz10ULay6WjybChJHh3sO6zWtuv865BsETRE365gt4d1woPVRmbOe2W0O/J2DuJ3DV0aEEUhMe6Bd+f3Hk+TWzP+dcg+IJoia9+Ghottq9d+W33bE7XHAXvDMGbjmr+s1fp7wKpc+GG9NrrVu9fTnnGiRvxVSTxg0Og++061y17Q/qA3M+hiHXhOav1Wl1dP/l0HxjOOzsqu/DOdegeQmipsyZHur8y/rtQ676DIBux8Ddf4KXH6/aPt4ZG6q6Si6DNdeuXjzOuQbLE0RNSXXl3a2av2do1Aj+eD9suyf843j48M3KbW8GD1wOLVvDIWdULxbnXIPmCaImmIXqpR32hY3aVrx+RZo2gyuGhx/bXXF46IU1V6WjYeprcOxfw36cc66KPEHUhBnvwqwPV/bcWhOabxR6f126JDR/XfxdxdukSg8bd4Bfn1xzsTjnGiRPEDVh7GAoagz7HF2z+223DfR7HGZ/BFf/vuLmrxNGwrRSOL5f7fUS65yrtzxBVNeKFTB+KOxyUH66stjpADjvDnjrObjt3LKbv65YEX413boTHHhCzcfhnGtwPEFUV2rc6eq2XirPwafAMX+Cp++Ex/+dfZ2Xh8GM90IngEXeetk5V31+JamucUPCuNN79crvcf7wtzBU6V1/DL2/7n3EymXLl8ODV0D7bavfiso55yIvQVTHsl/gpUdhj8NhzXXye6xGjeDSB2GrXeHaY8O9hpRxg8NN8hOuLL8HWeecqwRPENWRGnc6l55ba8Iaa8KAkbDBRtDvMPj685CkHr4StugKv/pt7cThnGsQPEFUx7ghsM4GsMuva++YzTcOvb8u+REuPxRG3Bqqnk4cEEoZzjlXQ/yKUlWpcaf3ORqarlG7x+6wHVw+LAwleudFsPVusMehtRuDc67ey2uCkNRT0keSpkvqm2X5DZImxcc0SQvTli1PWzYyn3FWyRv/LX/c6XzbpQecdzs0WQNO/nvluhd3zrkc5K0Vk6Qi4DagBzAbmChppJlNTa1jZhemrX8usFPaLn4ys675iq/axg6ueNzpfPvNaXDA8eHehHPO1bB8liB2A6ab2QwzWwoMBcprC9obGJLHeGpOruNO1wZPDs65PMlngmgNzEqbnh3nrUZSe6AjMDZtdjNJpZJel3REGdudHtcpnTdvXg2FnYPUuNM12feSc84VmEK5SV0CDDOz5Wnz2ptZMXAscKOkLTI3MrOBZlZsZsWtWrWqrVhXjju9VXHtHdM552pZPhPEHCC97+s2cV42JWRUL5nZnPh3BjCeVe9PJOebuVUbd9o55+qYfCaIiUAnSR0lNSUkgdVaI0nqDDQHJqTNay5pjfi8JbA3MDVz20S8+EjVx512zrk6JG+tmMxsmaRzgNFAEXCvmU2RNAAoNbNUsigBhpqt0k3pNsCdklYQkti16a2fEjVuSPXGnXbOuToir531mdkzwDMZ8/plTPfPst1rwA75jK1K5kyHj96EU/+ZdCTOOZd3hXKTum5IjTvdvSTZOJxzrhZ4gshVatzp7fepmXGnnXOuwHmCyFVq3Ona6rnVOecS5gkiV+OG5GfcaeecK1CeIHKxYkVIEPkad9o55wqQJ4hc1Ma40845V2A8QeSitsadds65AuIJoiK1Oe60c84VEE8QFXn7hdodd9o55wqEJ4iKjBtc++NOO+dcAfAEUZ4kx512zrmEeYIoT2rcae+51TnXAHmCKE9q3Oku3ZKOxDnnap0niLL8sABKR0G3Y5Ifd9o55xLgCaIsrzwBvyz11kvOuQbLE0RZxg/xcaedcw2aJ4hsvpkLk8bCfr193GnnXIPlCSKb1LjT+3nrJedcw+UJIptxQ2CLrtBum6Qjcc65xHiCyJQad9p7bnXONXCeIDKNHxr++rjTzrkGzhNEOjMYO8jHnXbOOfKcICT1lPSRpOmS+mZZfoOkSfExTdLCjOXrSZot6dZ8xvk/Pu60c879T+N87VhSEXAb0AOYDUyUNNLMpqbWMbML09Y/F9gpYzdXAS/lK8bV+LjTzjn3P/ksQewGTDezGWa2FBgKlDckW29gSGpC0i7AxsBzeYxxJR932jnnVpHPBNEamJU2PTvOW42k9kBHYGycbgRcD1xS3gEknS6pVFLpvHnzqhft1Nd83GnnnEtTKDepS4BhZrY8Tp8FPGNms8vbyMwGmlmxmRW3atWqehGMHezjTjvnXJq83YMA5gDpTYHaxHnZlABnp03vCewj6SxgHaCppEVmttqN7hrh404759xq8pkgJgKdJHUkJIYSYLX6G0mdgebAhNQ8MzsubflJQHHekgOsHHfau9Zwzrn/yVsVk5ktA84BRgMfAI+a2RRJAyQdnrZqCTDUzCxfsVQoNe50cc/EQnDOuUKjJK/LNam4uNhKS0srv+GSH+GYjcPAQBfdXfOBOedcAZP0lpllHdegUG5SJ2fxQtjjMDjwxKQjcc65gpLPexB1w4abwWWDk47COecKjpcgnHPOZeUJwjnnXFaeIJxzzmXlCcI551xWniCcc85l5QnCOedcVp4gnHPOZeUJwjnnXFb1pqsNSfOAz6qxi5bA/BoKpzbV1bjBY0+Kx56MQo29vZllHS+h3iSI6pJUWlZ/JIWsrsYNHntSPPZk1MXYvYrJOedcVp4gnHPOZeUJYqWBSQdQRXU1bvDYk+KxJ6POxe73IJxzzmXlJQjnnHNZeYJwzjmXVYNPEJJ6SvpI0nRJfZOOJ1eS2koaJ2mqpCmSzk86psqSVCTpHUn/TTqWypC0gaRhkj6U9IGkPZOOKReSLoznymRJQyQ1Szqm8ki6V9LXkianzWsh6XlJH8e/zZOMMZsy4r4uni/vSXpS0gYJhpizBp0gJBUBtwEHA9sCvSVtm2xUOVsGXGxm2wJ7AGfXodhTzgc+SDqIKrgJeNbMOgM7Ugdeg6TWwHlAsZltDxQBJclGVaH7gZ4Z8/oCY8ysEzAmThea+1k97ueB7c2sCzANuKy2g6qKBp0ggN2A6WY2w8yWAkOBXgnHlBMzm2tmb8fnPxAuUq2TjSp3ktoAhwB3Jx1LZUhaH9gXuAfAzJaa2cJEg8pdY2BNSY2BtYAvEo6nXGb2EvBtxuxewAPx+QPAEbUZUy6yxW1mz5nZsjj5OtCm1gOrgoaeIFoDs9KmZ1OHLrIpkjoAOwFvJBxKZdwIXAqsSDiOyuoIzAPui9Vjd0taO+mgKmJmc4B/AZ8Dc4HvzOy5ZKOqko3NbG58/iWwcZLBVNHJwKikg8hFQ08QdZ6kdYDHgQvM7Puk48mFpEOBr83sraRjqYLGwM7A7Wa2E7CYwqzmWEWsq+9FSHCbAWtLOj7ZqKrHQhv9OtVOX9JfCNXDg5KOJRcNPUHMAdqmTbeJ8+oESU0IyWGQmT2RdDyVsDdwuKSZhGq9/SU9nGxIOZsNzDazVGltGCFhFLoDgU/NbJ6Z/QI8AeyVcExV8ZWkTQHi368Tjidnkk4CDgWOszryA7SGniAmAp0kdZTUlHDTbmTCMeVEkgj14B+Y2b+TjqcyzOwyM2tjZh0I7/lYM6sT32bN7EtglqSt46wDgKkJhpSrz4E9JK0Vz50DqAM317MYCfSJz/sAIxKMJWeSehKqVA83sx+TjidXDTpBxJtG5wCjCR+WR81sSrJR5Wxv4ATCt+9J8fGbpINqIM4FBkl6D+gK/C3ZcCoWSzzDgLeB9wmf/YLu+kHSEGACsLWk2ZJOAa4Fekj6mFAqujbJGLMpI+5bgXWB5+Nn9Y5Eg8yRd7XhnHMuqwZdgnDOOVc2TxDOOeey8gThnHMuK08QzjnnsvIE4ZxzLitPEK5gSTJJ16dNXyKpfw3te1FN7Ke6+5Z0n6QzMuYdISnnrhgknSnpxArWuV/S0Vnmd69rvem62uMJwhWyn4HfSmqZxMFjp3b5NoTVe1UtifMrJKmxmd1hZg/WeGSuwfME4QrZMsKPuS7MXCCpg6SxsX/9MZLaxfn3S7pd0uuSZsRvyPfGcRvuz9jHDXF8hDGSWsV54yXdKKkUOF/SLpJelPSWpNGpbh4y9tNR0gRJ70u6OmPZHyVNjHFemeU1jgE6p3UfsTbhB2DDJfWL206WNDD+AjpbjP0lXRKXnRa3eVfS45LWSjvWgZJKJU2L/WFlvo6143v1ZuyIsFecv12cNym+jk7Z/12uvvEE4QrdbcBxsZvtdLcAD8T+9QcBN6ctaw7sSUgsI4EbgO2AHSR1jeusDZSa2XbAi8AVads3NbPiuM9bgKPNbBfgXuCaLDHeROi8bwdCT6kASDoI6EToVr4rsIukfdM3NLPlhP60fh9nHQaMjx0v3mpmu8bxG9Yk9OOzSoxmdj2reiJukxqn4pS0ZR1iLIcAd2j1AYP+Quj2ZDdgP+C6mLDOBG4ys65AMaE/KtcAeIJwBS1eKB8kDHaTbk9gcHz+EPCrtGVPxc7Q3ge+MrP3zWwFMIVwkYTQzfgj8fnDGdun5m8NbE/sHgH4K9n78d+blVVCD6XNPyg+3iF0cdGZkDAypVczpVcv7SfpDUnvA/sTklxmjJm2l/Ry3Oa4jG0eNbMVZvYxMCPGk+4goG98reOBZkA7QrcRf5b0J6C9mf1UxrFdPVMbdazOVdeNhAvsfTmu/3P8uyLteWq6rHM+vc+ZxfGvgClmlsuQotn6rBHwdzO7s4JtXwM2lbQjoYfVkvjt/j+EEeBmxZvz6d/4F6++GyCMZnaEmb2r0Hto93JizJwWcJSZfZQx/wNJbxBKHs9IOsPMxlbwmlw94CUIV/DM7FvgUVatLnmNld+6jwNeruRuGwGpVj3HAq9kWecjoJXimNOSmkjaLst6r2bEkjIaOFlhzA4ktZa0UebGsbTzCGGEtFFmtoSVyWB+3H61FkhlWBeYq9AV/HEZy34nqZGkLYDN4+tLNxo4N+1ex07x7+bADDO7mdB7apccY3F1nCcIV1dcD6S3ZjoX+INCj6onEMa3rozFwG4KA8vvDwzIXCEOQ3s08A9J7wKTyD6GwvmEMcHfJ21Ewjhi22BgQlw2jHABz2YIYXzrIXHbhcBdwGTChXtijq/rcsLIgq8CH2Ys+xx4kzCa2ZkxEaW7CmgCvCdpSpyGcH9kcqx62p5Q5ecaAO/N1TnnXFZegnDOOZeVJwjnnHNZeYJwzjmXlScI55xzWXmCcM45l5UnCOecc1l5gnDOOZfV/wOGlZ9rJ2Rt6AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accurVsVars(Xnorm_train, Xnorm_test, Ycr_train, Ycr_test, [i[1] for i in varsimpor_l])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  To recall, number of variables (x axis) is not the same as column order in the matrix [x=1 --> ('Income', 8),  x=2 --> ('Seniority', 0), x=3 --> ('Amount', 11), x=4 --> ('Price', 12), x=5 --> ('Age', 3), x=6 --> ('Assets', 9), x=7 --> ('Expenses', 7), x=8 --> ('Records', 5), x=9 --> ('Time', 2), x=10 --> ('Job', 6), x=11 --> ('Debt', 10), x=12 --> ('Home', 1), x=13 --> ('Marital', 4)] .  In this figure above, variables Time, Job, DEbt, Home, Marital are the reduntant ones. (Caution!, this changed several times even with random_state=1, in  some runs I have obtained only Marital as redundant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Accuracy vs variables (OPTIMIZED):</b> \n",
    " If redundant variables are detected it is necessary to filter them out and re-run tuning (GridCV) and crossvalidation. We have also to be careful with overfitting (*sur-apprentissage*): the model only capable to predict about specific data but not being able to generalize. This is frequent when 'noisy' variables are not correctly detected and excluded.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Heterogeneous Data\n",
    "## II.1 Data preparation and Normalization\n",
    "This new dataset is also related to bank clients, being the class to predict: credit aproval(1) vs rejection(0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "hetcr = pd.read_csv(\"credit.data\", sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.46</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1     2  3  4  5  6     7  8  9   10 11 12   13   14 15\n",
       "0  b  30.83  0.00  u  g  w  v  1.25  t  t   1  f  g  202    0  +\n",
       "1  a  58.67  4.46  u  g  q  h  3.04  t  t   6  f  g   43  560  +"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hetcr.head(2)  # as we see, column names are just numbers from 0 to 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "rawM = hetcr.values\n",
    "X = np.copy(rawM[:,0:15]) # variables caractéristiques\n",
    "Y = np.copy(rawM[:,15]) # var à prédire (target)\n",
    "Y[Y == '+'] = 1\n",
    "Y[Y == '-'] = 0\n",
    "Y = Y.astype(int)\n",
    "col_num = [1, 2, 7, 10, 13, 14 ]  # numerical vars\n",
    "col_cat = [i for i in range(15) if i not in col_num] # categorical\n",
    "print(np.isnan(Y[0]))  # check Y does not contain missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this credit.data we have categorical and numerical variables in same matrix, presenting **Missing values**, that will be treated.\n",
    "1.  A first approach using only numerical variables and droping out individuals having missing values\n",
    "2.  secondly, imputation method to both numerical and categorical missing values,  and concatenate both to run classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = np.copy(X[:, col_num])  # get only numerical\n",
    "X_num[X_num == '?'] = np.nan  # missing values in X set to nan\n",
    "X_num = X_num.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete subjects, from X and Y,  having nan in at least one column in X\n",
    "Ycut = Y[~np.isnan(X_num).any(axis=1)]\n",
    "Xnumcut = X_num[~np.isnan(X_num).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((666, 6), (666,))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnumcut.shape, Ycut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([367.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 299.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Ycut, color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([383.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 305.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y, color =\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "hetercl = run_classifiers(clfs, Xnumcut, Ycut) # a dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossvalidation on non-normalized numerical-only matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_sd</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_sd</th>\n",
       "      <th>AUC</th>\n",
       "      <th>time_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAG</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADA</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CART</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ID3</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ST</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  accuracy_mean  accuracy_sd  precision_mean  precision_sd    AUC  \\\n",
       "0         RF          0.790        0.042           0.803         0.034  0.855   \n",
       "3        BAG          0.785        0.044           0.781         0.048  0.839   \n",
       "2        ADA          0.781        0.023           0.790         0.053  0.830   \n",
       "6       CART          0.755        0.036           0.836         0.031  0.799   \n",
       "7        ID3          0.752        0.021           0.734         0.048  0.750   \n",
       "8         ST          0.743        0.042           0.861         0.064  0.722   \n",
       "4        MLP          0.737        0.036           0.748         0.033  0.816   \n",
       "5         NB          0.715        0.028           0.819         0.026  0.794   \n",
       "1        KNN          0.695        0.031           0.707         0.044  0.748   \n",
       "\n",
       "   time_s  \n",
       "0   0.176  \n",
       "3   0.206  \n",
       "2   0.135  \n",
       "6   0.008  \n",
       "7   0.008  \n",
       "8   0.006  \n",
       "4   0.467  \n",
       "5   0.006  \n",
       "1   0.008  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hetetab = pd.DataFrame.from_dict(hetercl)\n",
    "print(\"Crossvalidation on non-normalized numerical-only matrix:\")\n",
    "hetetab.sort_values(by=['accuracy_mean', 'precision_mean', 'AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this crossvalidation, we excluded all rows containing missing values. As we can see in the table above, ordered by accuracy, precision and AUC in descending values, **RF is the best classifier** . Below, the table with normalized matrix shows very similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Centered-reduced data:\n",
    "scaler = StandardScaler()\n",
    "Xnormcut = scaler.fit_transform(Xnumcut)\n",
    "heternorm = run_classifiers(clfs, Xnormcut, Ycut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossvalidation on *Normalized* numerical-only matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_sd</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_sd</th>\n",
       "      <th>AUC</th>\n",
       "      <th>time_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADA</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAG</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CART</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ID3</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ST</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  accuracy_mean  accuracy_sd  precision_mean  precision_sd    AUC  \\\n",
       "0         RF          0.791        0.046           0.806         0.040  0.855   \n",
       "2        ADA          0.781        0.023           0.790         0.053  0.830   \n",
       "3        BAG          0.776        0.046           0.780         0.033  0.832   \n",
       "4        MLP          0.773        0.026           0.806         0.008  0.846   \n",
       "6       CART          0.755        0.036           0.836         0.031  0.799   \n",
       "7        ID3          0.752        0.021           0.734         0.048  0.750   \n",
       "1        KNN          0.751        0.048           0.814         0.046  0.833   \n",
       "8         ST          0.743        0.042           0.861         0.064  0.722   \n",
       "5         NB          0.715        0.028           0.819         0.026  0.794   \n",
       "\n",
       "   time_s  \n",
       "0   0.169  \n",
       "2   0.139  \n",
       "3   0.215  \n",
       "4   0.493  \n",
       "6   0.007  \n",
       "7   0.009  \n",
       "1   0.009  \n",
       "8   0.006  \n",
       "5   0.006  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heter_nrm_t =  pd.DataFrame.from_dict(heternorm)\n",
    "print(\"Crossvalidation on *Normalized* numerical-only matrix:\")\n",
    "heter_nrm_t.sort_values(by=['accuracy_mean', 'precision_mean', 'AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## II.2 Treat Missing values : *imputer*\n",
    "Preserve full X matrix,  impute variables including categorical ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treat numerical variables : \n",
    "imp_num = Imputer(missing_values=np.nan, strategy='mean')\n",
    "X_num = imp_num.fit_transform(X_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# treat categorical variables\n",
    "X_cat = np.copy(X[:, col_cat])\n",
    "for col_id in range(len(col_cat)):\n",
    "    unique_val, val_idx = np.unique(X_cat[:, col_id], return_inverse=True)\n",
    "    X_cat[:, col_id] = val_idx\n",
    "imp_cat = Imputer(missing_values=0, strategy='most_frequent')\n",
    "X_cat[:, range(5)] = imp_cat.fit_transform(X_cat[:, range(5)])\n",
    "# to be able to use in run_classifiers, for a given variable\n",
    "# transform m categories into m binary vars, being only one active\n",
    "X_cat_bin = OneHotEncoder().fit_transform(X_cat).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(688, 46)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xmerge = np.concatenate((X_num,X_cat_bin),axis=1)\n",
    "Xmerge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_sd</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_sd</th>\n",
       "      <th>AUC</th>\n",
       "      <th>time_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAG</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ST</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADA</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CART</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ID3</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  accuracy_mean  accuracy_sd  precision_mean  precision_sd    AUC  \\\n",
       "0         RF          0.866        0.023           0.843         0.043  0.933   \n",
       "3        BAG          0.863        0.019           0.839         0.049  0.925   \n",
       "8         ST          0.856        0.036           0.789         0.056  0.864   \n",
       "2        ADA          0.843        0.029           0.825         0.038  0.917   \n",
       "5         NB          0.839        0.020           0.855         0.029  0.918   \n",
       "6       CART          0.833        0.013           0.802         0.072  0.907   \n",
       "7        ID3          0.817        0.028           0.798         0.035  0.813   \n",
       "4        MLP          0.797        0.055           0.783         0.061  0.861   \n",
       "1        KNN          0.673        0.040           0.674         0.050  0.731   \n",
       "\n",
       "   time_s  \n",
       "0   0.180  \n",
       "3   0.262  \n",
       "8   0.007  \n",
       "2   0.156  \n",
       "5   0.007  \n",
       "6   0.008  \n",
       "7   0.011  \n",
       "4   0.548  \n",
       "1   0.011  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hetefull = run_classifiers(clfs, Xmerge, Y)\n",
    "hetefulltab = pd.DataFrame.from_dict(hetefull)\n",
    "hetefulltab.sort_values(by=['accuracy_mean', 'precision_mean', 'AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above for this imputed dataset shows still RF(Random Forest) and BAG as best classifiers, however an important change occured in terms of prediction between \"amputated\" (rows with missing values just suppressed) vs imputed values.\n",
    "\n",
    "The table below table contains **Random Forest** results on both types of data demonstrates that imputation improves the capacity of the model to achieve better parameters, we deduce that performance in prediction has boost, and it is also reflected in computational time which is also improved:\n",
    "\n",
    "\n",
    "| RF on data...           | ACCURACY | PRECISION | AUC   | time  |\n",
    "|-------------------------|----------|-----------|-------|-------|\n",
    "| with 'amputated' values | 0.790    | 0.803     | 0.855 | 0.373 |\n",
    "| with imputed variables  | **0.866**    | 0.848     | **0.933** | 0.361 |\n",
    "|                         |          |           |       |       |\n",
    "\n",
    "This case illustrates that RF has a high performance for distinguishing between clients with approved credit(positive cases) from those rejected (negative cases), as reflected here by AUC (93,3%) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Textual data : Feature engineering et Classification\n",
    "## III.1 SMS data\n",
    "We need to distinguish true messages (\"ham\") from spam. As we do not want to lose true messages (at risk of allowing some false positives, i.e. spam being wrongly classified as sms), we select accuracy, **RECALL** and AUC as criteria to judge classifier performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smsall = pd.read_csv(\"SMSSpamCollection.data\", sep=\"\\t\", header=None)\n",
    "smsall.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preXsms = smsall.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = np.copy(preXsms[:,1])\n",
    "Ys = np.copy(preXsms[:,0])\n",
    "\n",
    "Ys[Ys == 'ham'] = 1\n",
    "Ys[Ys == 'spam'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true messages(ham) 86.59 %, Spam : 13.41%\n"
     ]
    }
   ],
   "source": [
    "HAM = 100*np.sum(Ys==1)/len(Ys) \n",
    "SPAM = 100*np.sum(Ys==0)/len(Ys) \n",
    "print ('true messages(ham) {0:.2f} %, Spam : {1:.2f}%'.format(HAM,SPAM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " captured features :8444\n"
     ]
    }
   ],
   "source": [
    "# I set max_features around that value (incremented by safety )\n",
    "vectorizer1 = CountVectorizer(stop_words=\"english\", analyzer='word') \n",
    "# analyzer 'word' is default anyway\n",
    "Xsv1 = vectorizer1.fit_transform(list(Xs))\n",
    "print(f' captured features :{len(vectorizer1.get_feature_names())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>CountVectorizer:</b> it produces a SPARSE MATRIX (many zero values)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifiersII(clfs, X, Y):\n",
    "    dico = {'classifier':[],'accuracy_mean':[],'accuracy_sd':[], \n",
    "            'recall_mean':[], 'recall_sd':[],\n",
    "             'precision_mean':[], 'precision_sd':[],\n",
    "            'AUC':[], 'time_s':[]} #output into dictionnary\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    for clf_id in clfs:\n",
    "        initime = time.time()\n",
    "        clf = clfs[clf_id]\n",
    "        cvAccur = cross_val_score(clf, X, Y, cv=kf, n_jobs=4)\n",
    "        end = time.time()\n",
    "        cvPrecision = cross_val_score(clf, X, Y, cv=kf, scoring='precision', n_jobs=4)\n",
    "        cvRecall = cross_val_score(clf, X, Y, cv=kf, scoring='recall', n_jobs=4)\n",
    "        cvAUC = cross_val_score(clf, X, Y, cv=kf, scoring='roc_auc', n_jobs=4)\n",
    "        dico['classifier'].append(clf_id)\n",
    "        dico['accuracy_mean'].append(round(np.mean(cvAccur),3))\n",
    "        dico['accuracy_sd'].append(round(np.std(cvAccur),3))\n",
    "        dico['precision_mean'].append(round(np.mean(cvPrecision),3))\n",
    "        dico['precision_sd'].append(round(np.std(cvPrecision),3))\n",
    "        dico['recall_mean'].append(round(np.mean(cvRecall),3))\n",
    "        dico['recall_sd'].append(round(np.std(cvRecall),3))\n",
    "        dico['AUC'].append(round(np.mean(cvAUC),3))\n",
    "        dico['time_s'].append(round((end-initime),3))\n",
    "    return dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfsB = {    \n",
    "    'RF': RandomForestClassifier(n_estimators=50, random_state=1),\n",
    "    'MLP' : MLPClassifier(activation='tanh', alpha=0.001, \n",
    "                          hidden_layer_sizes=(50, 30), max_iter=100, solver='adam'),\n",
    "    'ADA' : AdaBoostClassifier(n_estimators=50, random_state=1),\n",
    "    'BAG' : BaggingClassifier(n_estimators=50),\n",
    "    'CART' : DecisionTreeClassifier(random_state=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsv1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-82c7db28e165>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdicoSparse1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_classifiersII\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclfsB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXsv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-4d6e5daea37a>\u001b[0m in \u001b[0;36mrun_classifiersII\u001b[0;34m(clfs, X, Y)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcvAccur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mcvPrecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mcvRecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mcvAUC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/venv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    402\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/venv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 242\u001b[0;31m     scores = parallel(\n\u001b[0m\u001b[1;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/venv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/venv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/venv/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dicoSparse1 = run_classifiersII(clfsB, Xsv1.toarray(), list(Ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dicoSparse1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-bfbad5f46079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSparsetab1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicoSparse1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mSparsetab1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy_mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall_mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'AUC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dicoSparse1' is not defined"
     ]
    }
   ],
   "source": [
    "Sparsetab1 = pd.DataFrame.from_dict(dicoSparse1)\n",
    "Sparsetab1.sort_values(by=['accuracy_mean', 'recall_mean','AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In last file opening I mistakenly re-run when variables no longer available, here the copy of the result for `dicoSparse1` (enormous time):\n",
    "\n",
    "\n",
    "|   | classifier | accuracy_mean | accuracy_sd | recall_mean | recall_sd | precision_mean | precision_sd |   AUC |  time_s |   |   |   |   |\n",
    "|--:|-----------:|--------------:|------------:|------------:|----------:|---------------:|-------------:|------:|--------:|---|---|---|---|\n",
    "| 1 | MLP        | 0.984         | 0.004       | 1.000       | 0.001     | 0.982          | 0.004        | 0.986 | 69.815  |   |   |   |   |\n",
    "| 0 | RF         | 0.978         | 0.006       | 0.999       | 0.001     | 0.975          | 0.007        | 0.990 | 42.767  |   |   |   |   |\n",
    "| 3 | BAG        | 0.975         | 0.005       | 0.992       | 0.002     | 0.977          | 0.006        | 0.978 | 541.908 |   |   |   |   |\n",
    "| 4 | CART       | 0.971         | 0.004       | 0.989       | 0.003     | 0.978          | 0.005        | 0.923 | 47.644  |   |   |   |   |\n",
    "| 2 | ADA        | 0.968         | 0.003       | 0.993       | 0.002     | 0.971          | 0.003        | 0.963 | 80.814  |   |   |   |   |\n",
    "|   |            |               |             |             |           |                |              |       |         |   |   |   |   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1 = TfidfTransformer()\n",
    "Xtf1 = tf1.fit_transform(Xsv1)\n",
    "dicoSparse2 = run_classifiersII(clfsB, Xtf1, list(Ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_sd</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_sd</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_sd</th>\n",
       "      <th>AUC</th>\n",
       "      <th>time_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.993</td>\n",
       "      <td>37.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.993</td>\n",
       "      <td>4.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAG</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.983</td>\n",
       "      <td>10.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CART</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADA</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.961</td>\n",
       "      <td>2.326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  accuracy_mean  accuracy_sd  recall_mean  recall_sd  \\\n",
       "1        MLP          0.981        0.006        0.999      0.001   \n",
       "0         RF          0.977        0.005        1.000      0.001   \n",
       "3        BAG          0.973        0.004        0.990      0.004   \n",
       "4       CART          0.968        0.008        0.986      0.004   \n",
       "2        ADA          0.967        0.004        0.992      0.003   \n",
       "\n",
       "   precision_mean  precision_sd    AUC  time_s  \n",
       "1           0.981         0.006  0.993  37.758  \n",
       "0           0.974         0.006  0.993   4.021  \n",
       "3           0.979         0.006  0.983  10.739  \n",
       "4           0.977         0.006  0.918   0.416  \n",
       "2           0.970         0.003  0.961   2.326  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sparsetab2 = pd.DataFrame.from_dict(dicoSparse2)\n",
    "Sparsetab2.sort_values(by=['accuracy_mean', 'recall_mean', 'AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd1 = TruncatedSVD(n_components=2)\n",
    "Xsvd1 = svd1.fit_transform(Xtf1)\n",
    "dicoSparse3 = run_classifiersII(clfsB, Xsvd1, list(Ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_sd</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_sd</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_sd</th>\n",
       "      <th>AUC</th>\n",
       "      <th>time_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAG</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.014</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.650</td>\n",
       "      <td>1.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADA</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CART</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  accuracy_mean  accuracy_sd  recall_mean  recall_sd  \\\n",
       "0         RF          0.878        0.012        0.959      0.006   \n",
       "3        BAG          0.871        0.013        0.950      0.004   \n",
       "1        MLP          0.866        0.014        1.000      0.000   \n",
       "2        ADA          0.865        0.014        0.999      0.001   \n",
       "4       CART          0.835        0.003        0.896      0.005   \n",
       "\n",
       "   precision_mean  precision_sd    AUC  time_s  \n",
       "0           0.905         0.012  0.792   0.528  \n",
       "3           0.908         0.014  0.790   0.761  \n",
       "1           0.866         0.014  0.650   1.977  \n",
       "2           0.866         0.014  0.741   0.302  \n",
       "4           0.911         0.008  0.662   0.040  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sparsetab3 = pd.DataFrame.from_dict(dicoSparse3)\n",
    "Sparsetab3.sort_values(by=['accuracy_mean', 'recall_mean', 'AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this TEXT MINING context we are interested in capturing true sms, we need the highest recall so I modified function (run_classifiersII) to get this parameter. The Classifier allowing to obtain best **accuracy**,**AUC** and **recall** will be chosen (our \"target\" ) to build de pipeline. Firstly, we have tested different classifiers on  'SMSSpamCollection' data in three progressive scenarios (three tables above):\n",
    " - on the sparse matrix :\n",
    "     - MLP and RF yield the highest target parameters\n",
    "     - accuracy, recall and AUC optimal to our purposes, but a the cost of important computational time\n",
    " - on sparse + weighted matrix (TfidfTransformer) : \n",
    "      - MLP and RF yield the highest target parameters\n",
    "      - still time consumming, specially MLP\n",
    " - on sparse + weighted + linear dimensionality reduction (TruncatedSVD) : \n",
    "     - RF and BAG yield the highest target parameters\n",
    "     - slightly negative impact in AUC, accuracy and recall but a remarkable **gain in performance** reflected by reduced computationnal times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "tft_tsvd = FeatureUnion([  ('tft', TfidfTransformer()), \n",
    "                         ('tsvd' , TruncatedSVD(n_components=2)) ])\n",
    "pipelineText = Pipeline( [\n",
    "    ('TfidfTransform_TruncatedSVD', tft_tsvd ),\n",
    "    ( 'RF' , RandomForestClassifier(n_estimators=50, random_state=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting SPARSE MATRIX : train (70% of the data) and test \n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(Xsv1.toarray(), list(Ys), test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('TfidfTransform_TruncatedSVD',\n",
       "                 FeatureUnion(transformer_list=[('tft', TfidfTransformer()),\n",
       "                                                ('tsvd', TruncatedSVD())])),\n",
       "                ('RF',\n",
       "                 RandomForestClassifier(n_estimators=50, random_state=1))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineText.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9766746411483254\n",
      "0.9979195561719834\n",
      "0.9206989085207744\n"
     ]
    }
   ],
   "source": [
    "prsms = pipelineText.predict(X_test)\n",
    "confusion_matrix(Y_test, prsms)\n",
    "print(accuracy_score(Y_test,prsms))\n",
    "print(recall_score(Y_test,prsms))\n",
    "print(roc_auc_score(Y_test,prsms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fileo = open(\"pipeTEXT.pkl\", 'wb')\n",
    "pickle.dump(pipelineText, fileo) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline** was used here to train the model. It requires as input the sparse matrix i.e. the one obtained with 'CountVectorizer'. I have splitted X and Y for demonstration purposes, to show prediction and confusion matrix derived scores. When new data become available (let's call it \"Xnew\"), by using :\n",
    "```ppline=pickle.load(open( \"pipeTEXT.pkl\", \"rb\" ) ) \n",
    " ppline.predict_proba(Xnew)```\n",
    " \n",
    "a prediction on these new data becomes available "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.2 YELP data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YELP contains two columns: 'Stars' can be 1 2 3 4 or 5 ; 'Text': all comments typed by clients/users/individuals about diverse services/stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp = pd.read_csv(\"yelp-text-by-stars.csv\", sep=\";\", header=0, encoding='latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Boarded my English Mastiff here over New Year'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars                                               Text\n",
       "0      1  Boarded my English Mastiff here over New Year'..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47371, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preXc = yelp.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the pipeline previously trained with SMS data, we can only predict true messages vs spam, lets treat then the situation as a simple bi-label classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " captured features :62617\n"
     ]
    }
   ],
   "source": [
    "pXc = np.copy(preXc[:,1])\n",
    "Yc = np.copy(preXc[:,0])\n",
    "\n",
    "vectorizer2 = CountVectorizer(stop_words=\"english\", analyzer='word') \n",
    "\n",
    "Xc = vectorizer2.fit_transform(pXc)\n",
    "print(f' captured features :{len(vectorizer2.get_feature_names())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prsms = pipelineText.predict(Xc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When I run `prsms = pipelineText.predict(Xc)` I get this I get error \"Input has n_features=62617 while the model has been trained with n_features=8444\", I wont be able to predict sms vs spam with this strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### APPENDIX : YELP  multilabel problem (stars)\n",
    "Taking the classification problem from another angle, we may be interested in predicting stars based on text content: the **multilabel** class 'star'. Here, distinguishing between true messages vs Spam is no longer the goal, learning step is necessary for this specific case.\n",
    "\n",
    "(NOTE: this part ran at internship lab computer (RAM 32Gib), impossible to allocate memory in my 8G RAM laptop)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "we run the pipeline built before, however, nature of the problem is different and this time class is multilabel, \n",
    "learning step is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l, X_t, Y_l, Y_t = model_selection.train_test_split(Xc.toarray(), list(Yc), test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pplineText=pickle.load(open( \"pipeTEXT.pkl\", \"rb\" ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1188,   23,   30,  135,  581],\n",
       "       [ 339,   31,   85,  249,  552],\n",
       "       [ 139,   11,  122,  641,  771],\n",
       "       [  61,    1,   56,  921, 2313],\n",
       "       [  53,    0,   11,  425, 5474]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pplineText.fit(X_l, Y_l)\n",
    "preds = pplineText.predict(X_t)\n",
    "confusion_matrix(Y_t,preds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[1188,   23,   30,  135,  581],\n",
    "       [ 339,   31,   85,  249,  552],\n",
    "       [ 139,   11,  122,  641,  771],\n",
    "       [  61,    1,   56,  921, 2313],\n",
    "       [  53,    0,   11,  425, 5474]])  # multilabel Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5443287362792006\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_t,preds))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.5443287362792006  # accuracy for multilabel prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, multilabel classification needs specific tunning and **benchmarking** additionnal classifiers such as Naive Bayes, SVM, etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
